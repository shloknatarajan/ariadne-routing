{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstream_router\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamRouter\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import training updates and test prompts from the external file.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mideation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TRAIN_UPDATES, TEST_PROMPTS\n",
      "File \u001b[0;32m~/Desktop/Random Projects/ariadne-routing/stream_router.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from stream_router import StreamRouter\n",
    "\n",
    "# Import training updates and test prompts from the external file.\n",
    "from ideation import TRAIN_UPDATES, TEST_PROMPTS\n",
    "\n",
    "# Create a router with 5 clusters and 8 diverse agents.\n",
    "agents = [\"HR Agent\", \"Code Generation Agent\",\"Web Search Agent\", \"Customer Service Agent\", \"Database Agent\"]\n",
    "# agents = [\"Math Agent\", \"Coding Agent\", \"HR Agent\", \"General\", \"Deep Research\", \"Image Gen\", \"GPT 4o\", \"GPT o3-mini-high\", \"Chemistry RAG\"]\n",
    "router = StreamRouter(agents, alpha=-0.0, embedding_dim=8, learning_rate=0.1, min_samples=8, model_name = \"Alibaba-NLP/gte-large-en-v1.5\")\n",
    "\n",
    "for prompt, agent in TRAIN_UPDATES:\n",
    "    router.update(prompt, agent)\n",
    "print(f\"Total clusters formed after training update: {len(router.clusters)}\")\n",
    "\n",
    "# Debug: Print cluster details.\n",
    "# router.debug_clusters()\n",
    "\n",
    "# Execute test inferences using the imported test prompts.\n",
    "print(\"\\nTest Inference Results:\")\n",
    "for i, prompt in enumerate(TEST_PROMPTS, start=1):\n",
    "    predicted_agent = router.inference(prompt)\n",
    "    print(f\"\\nTest Prompt {i}: \\\"{prompt}\\\"\")\n",
    "    print(f\"Predicted Agent: {predicted_agent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average intra-cluster cosine similarity: 0.270\n",
      "Average cross-cluster cosine similarity: 0.174\n"
     ]
    }
   ],
   "source": [
    "# Calculate average intra-cluster and cross-cluster distances using cosine similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get embeddings for all training prompts\n",
    "all_embeddings = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "# Split into 5 clusters of 10 prompts each\n",
    "clusters = []\n",
    "for i in range(0, 50, 10):\n",
    "    clusters.append(all_embeddings[i:i+10])\n",
    "\n",
    "# Calculate average intra-cluster similarities\n",
    "intra_cluster_sims = []\n",
    "for cluster in clusters:\n",
    "    # Get all pairwise similarities within cluster\n",
    "    sims = cosine_similarity(cluster)\n",
    "    # Get upper triangle only (excluding diagonal)\n",
    "    upper_tri = sims[np.triu_indices_from(sims, k=1)]\n",
    "    if len(upper_tri) > 0:\n",
    "        intra_cluster_sims.append(np.mean(upper_tri))\n",
    "\n",
    "avg_intra_sim = np.mean(intra_cluster_sims)\n",
    "print(f\"Average intra-cluster cosine similarity: {avg_intra_sim:.3f}\")\n",
    "\n",
    "# Calculate average cross-cluster similarities\n",
    "cross_cluster_sims = []\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i+1, len(clusters)):\n",
    "        sims = cosine_similarity(clusters[i], clusters[j])\n",
    "        cross_cluster_sims.append(np.mean(sims))\n",
    "\n",
    "avg_cross_sim = np.mean(cross_cluster_sims)\n",
    "print(f\"Average cross-cluster cosine similarity: {avg_cross_sim:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "  - Write a Dockerfile for a Node.js application with Express and PostgreSQL.\n",
      "  - Create a Terraform script to provision an AWS EC2 instance and configure security groups.\n",
      "  - Generate a Kubernetes deployment YAML file for a Flask web application.\n",
      "  - Find documentation for the latest version of Kubernetes.\n",
      "\n",
      "Cluster 1:\n",
      "  - Create a SQL query to retrieve the top 10 highest-paying customers from our database.\n",
      "  - Find the total number of employees working in the company and provide a breakdown by department.\n",
      "  - List all employees who joined the company after January 1, 2023.\n",
      "  - Get the email addresses of all team leads in the engineering department.\n",
      "  - Show me the employee with the highest salary in the company.\n",
      "  - Provide a list of employees along with their job titles and phone numbers.\n",
      "  - Fetch all employees who report to [Manager Name].\n",
      "  - Generate a list of employees whose work anniversary is this month.\n",
      "  - Find employees who have been with the company for more than five years.\n",
      "  - Retrieve a list of employees along with their assigned projects.\n",
      "\n",
      "Cluster 2:\n",
      "  - Get the most recent updates on AWS pricing changes.\n",
      "  - Search for trending front-end frameworks in 2025 and compare their adoption rates.\n",
      "  - Look up salary benchmarks for software engineers in San Francisco.\n",
      "  - Search for recent tech layoffs and industry hiring trends.\n",
      "  - Find the best practices for optimizing large-scale database queries in PostgreSQL.\n",
      "  - Check if there are any regulatory changes affecting fintech apps in Europe.\n",
      "  - Look up competitor product releases and announcements from the past month.\n",
      "  - Find recent blog posts or research papers on AI-powered code generation.\n",
      "  - I need to downgrade my subscription—what features will I lose?\n",
      "  - Provide a compatibility check—will your product work with my tech stack?\n",
      "  - Send me the latest changelog and release notes for your product.\n",
      "\n",
      "Cluster 3:\n",
      "  - Provide steps to integrate your API with my existing application.\n",
      "  - I'm experiencing latency issues with your cloud service—how can I fix this?\n",
      "  - Explain the security measures in place for protecting my account data.\n",
      "  - How do I set up multi-factor authentication for better security?\n",
      "\n",
      "Cluster 4:\n",
      "  - How do I request time off?\n",
      "  - Can you help me find my last three pay stubs?\n",
      "  - What is the process for filing a workplace complaint?\n",
      "  - How do I update my direct deposit information?\n",
      "  - Can you generate an employment verification letter for me?\n",
      "  - Can you help me migrate my data from another platform to your service?\n",
      "  - My software license key isn't working—how do I generate a new one?\n",
      "\n",
      "Cluster 5:\n",
      "  - Generate a Python script to automate file renaming in a directory based on a pattern.\n",
      "  - Write a Python script to scrape product prices from an e-commerce website and store them in a CSV file.\n",
      "\n",
      "Cluster 6:\n",
      "  - What are the company's healthcare benefits?\n",
      "  - What training programs or career development resources are available?\n",
      "  - Who do I contact for questions about my 401(k)?\n",
      "  - What is the company's remote work policy?\n",
      "\n",
      "Cluster 7:\n",
      "  - Write a function in JavaScript to validate email addresses using regex.\n",
      "  - Generate a React component for a dynamic search bar with autocomplete.\n",
      "  - Write a unit test suite in Jest for a function that processes user authentication.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Get embeddings for all training prompts\n",
    "train_embeddings = []\n",
    "train_prompts = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    train_embeddings.append(emb.numpy())\n",
    "    train_prompts.append(prompt)\n",
    "\n",
    "# Convert to numpy array\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "clusters = kmeans.fit_predict(train_embeddings)\n",
    "\n",
    "# Print prompts in each cluster\n",
    "for i in range(8):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    cluster_prompts = [prompt for j, prompt in enumerate(train_prompts) if clusters[j] == i]\n",
    "    for prompt in cluster_prompts:\n",
    "        print(f\"  - {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(router.clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "router",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
