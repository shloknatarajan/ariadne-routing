{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters formed after training update: 81\n",
      "\n",
      "Test Inference Results:\n",
      "\n",
      "Test Prompt 1: \"I have an issue with Workday. My hours weren't updated properly.\"\n",
      "Predicted Agent: HR Agent\n",
      "\n",
      "Test Prompt 2: \"Generate a Python script to fetch data from a REST API and store it in a database.\"\n",
      "Predicted Agent: Code Generation Agent\n",
      "\n",
      "Test Prompt 3: \"Find the latest security vulnerabilities in Python libraries we use.\"\n",
      "Predicted Agent: Web Search Agent\n",
      "\n",
      "Test Prompt 4: \"Help me troubleshoot why my SaaS account is locked.\"\n",
      "Predicted Agent: Customer Service Agent\n",
      "\n",
      "Test Prompt 5: \"Retrieve the contact details of all employees in the marketing department.\"\n",
      "Predicted Agent: Code Generation Agent\n",
      "\n",
      "Test Prompt 6: \"Schedule a meeting with the engineering and marketing teams next Wednesday at 10 AM and send out invites.\"\n",
      "Predicted Agent: Executive Assistant Agent\n",
      "\n",
      "Test Prompt 7: \"Review the terms of service for our new SaaS product and ensure compliance with GDPR and CCPA.\"\n",
      "Predicted Agent: Legal Agent\n",
      "\n",
      "Test Prompt 8: \"Generate a set of test cases for the login functionality, including valid, invalid, and edge cases.\"\n",
      "Predicted Agent: Software QA Agent\n",
      "\n",
      "Test Prompt 9: \"Check my system's CPU and memory usage and report any high resource consumption.\"\n",
      "Predicted Agent: Web Automation Agent\n"
     ]
    }
   ],
   "source": [
    "from stream_router import StreamRouter\n",
    "\n",
    "# Import training updates and test prompts from the external file.\n",
    "from ideation import TRAIN_UPDATES, TEST_PROMPTS\n",
    "\n",
    "router = StreamRouter([], embedding_dim=8, learning_rate=0.1, min_samples=8)\n",
    "\n",
    "for i in range(0, len(TRAIN_UPDATES), 9):\n",
    "    batch = TRAIN_UPDATES[i:i+9]\n",
    "    if batch:  # Only process if we have examples\n",
    "        agent = batch[0][1]  # Get agent name from first example\n",
    "        prompts = [p[0] for p in batch]  # Extract just the prompts\n",
    "        # print(agent, prompts)\n",
    "        router.add_agent(agent, prompts)\n",
    "\n",
    "for prompt, agent in TRAIN_UPDATES:\n",
    "    router.update(prompt, agent)\n",
    "print(f\"Total clusters formed after training update: {len(router.clusters)}\")\n",
    "\n",
    "# Debug: Print cluster details.\n",
    "# router.debug_clusters()\n",
    "\n",
    "# Execute test inferences using the imported test prompts.\n",
    "print(\"\\nTest Inference Results:\")\n",
    "for i, prompt in enumerate(TEST_PROMPTS, start=1):\n",
    "    predicted_agent = router.inference(prompt)\n",
    "    print(f\"\\nTest Prompt {i}: \\\"{prompt}\\\"\")\n",
    "    print(f\"Predicted Agent: {predicted_agent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster-Agent Embedding Similarities:\n",
      "--------------------------------------------------------------------------------\n",
      "Cluster 0 <-> HR Agent: 0.9969\n",
      "Cluster 1 <-> Code Generation Agent: 0.9061\n",
      "Cluster 2 <-> Web Search Agent: 0.9977\n",
      "Cluster 3 <-> Customer Service Agent: 0.9951\n",
      "Cluster 4 <-> Database Agent: 0.8729\n",
      "Cluster 4 <-> Code Generation Agent: 0.9833\n",
      "Cluster 5 <-> Executive Assistant Agent: 0.9974\n",
      "Cluster 6 <-> Legal Agent: 0.9961\n",
      "Cluster 7 <-> Software QA Agent: 0.9923\n",
      "Cluster 8 <-> Web Automation Agent: 0.9987\n"
     ]
    }
   ],
   "source": [
    "# Measure cosine similarity between cluster embeddings and agent embeddings\n",
    "print(\"\\nCluster-Agent Embedding Similarities:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, cluster in enumerate(router.clusters):\n",
    "    if cluster[\"embedding\"] is not None:  # Only check clusters with learned embeddings\n",
    "        # Get all agents used in this cluster\n",
    "        agents_in_cluster = set(agent for _, agent in cluster[\"data\"])\n",
    "        \n",
    "        for agent in agents_in_cluster:\n",
    "            similarity = router._similarity(\n",
    "                cluster[\"embedding\"],\n",
    "                router.agent_embeddings[agent]\n",
    "            )\n",
    "            print(f\"Cluster {i} <-> {agent}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster-Agent Embedding Similarities:\n",
      "--------------------------------------------------------------------------------\n",
      "Cluster 0 <-> HR Agent: 0.9969\n",
      "Cluster 1 <-> Code Generation Agent: 0.9061\n",
      "Cluster 2 <-> Web Search Agent: 0.9977\n",
      "Cluster 3 <-> Customer Service Agent: 0.9951\n",
      "Cluster 4 <-> Database Agent: 0.8729\n",
      "Cluster 4 <-> Code Generation Agent: 0.9833\n",
      "Cluster 5 <-> Executive Assistant Agent: 0.9974\n",
      "Cluster 6 <-> Legal Agent: 0.9961\n",
      "Cluster 7 <-> Software QA Agent: 0.9923\n",
      "Cluster 8 <-> Web Automation Agent: 0.9987\n"
     ]
    }
   ],
   "source": [
    "# Measure cosine similarity between cluster embeddings and agent embeddings\n",
    "print(\"\\nCluster-Agent Embedding Similarities:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, cluster in enumerate(router.clusters):\n",
    "    if cluster[\"embedding\"] is not None:  # Only check clusters with learned embeddings\n",
    "        # Get all agents used in this cluster\n",
    "        agents_in_cluster = set(agent for _, agent in cluster[\"data\"])\n",
    "        \n",
    "        for agent in agents_in_cluster:\n",
    "            similarity = router._similarity(\n",
    "                cluster[\"embedding\"],\n",
    "                router.agent_embeddings[agent]\n",
    "            )\n",
    "            print(f\"Cluster {i} <-> {agent}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors analysis:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Can you help me migrate my data from another platform to your service?\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.562 - \"Provide steps to integrate your API with my existing application.\"\n",
      "Distance: 0.638 - \"I'm experiencing latency issues with your cloud service—how can I fix this?\"\n",
      "Distance: 0.659 - \"Provide a compatibility check—will your product work with my tech stack?\"\n",
      "Distance: 0.690 - \"Can you generate an employment verification letter for me?\"\n",
      "Distance: 0.692 - \"Explain the security measures in place for protecting my account data.\"\n",
      "Distance: 0.713 - \"I need to downgrade my subscription—what features will I lose?\"\n",
      "Distance: 0.735 - \"Send me the latest changelog and release notes for your product.\"\n",
      "Distance: 0.739 - \"Can you help me find my last three pay stubs?\"\n",
      "Distance: 0.761 - \"Write a Python script to scrape product prices from an e-commerce website and store them in a CSV file.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Search for trending front-end frameworks in 2025 and compare their adoption rates.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.554 - \"Search for recent tech layoffs and industry hiring trends.\"\n",
      "Distance: 0.614 - \"Look up competitor product releases and announcements from the past month.\"\n",
      "Distance: 0.639 - \"Check if there are any regulatory changes affecting fintech apps in Europe.\"\n",
      "Distance: 0.649 - \"Find recent blog posts or research papers on AI-powered code generation.\"\n",
      "Distance: 0.651 - \"Provide a compatibility check—will your product work with my tech stack?\"\n",
      "Distance: 0.667 - \"Generate a React component for a dynamic search bar with autocomplete.\"\n",
      "Distance: 0.672 - \"Look up salary benchmarks for software engineers in San Francisco.\"\n",
      "Distance: 0.707 - \"Get the most recent updates on AWS pricing changes.\"\n",
      "Distance: 0.744 - \"Find documentation for the latest version of Kubernetes.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Look up competitor product releases and announcements from the past month.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.494 - \"Search for recent tech layoffs and industry hiring trends.\"\n",
      "Distance: 0.500 - \"Send me the latest changelog and release notes for your product.\"\n",
      "Distance: 0.529 - \"Get the most recent updates on AWS pricing changes.\"\n",
      "Distance: 0.614 - \"Search for trending front-end frameworks in 2025 and compare their adoption rates.\"\n",
      "Distance: 0.616 - \"Check if there are any regulatory changes affecting fintech apps in Europe.\"\n",
      "Distance: 0.628 - \"Provide a compatibility check—will your product work with my tech stack?\"\n",
      "Distance: 0.655 - \"Generate a list of employees whose work anniversary is this month.\"\n",
      "Distance: 0.666 - \"Find documentation for the latest version of Kubernetes.\"\n",
      "Distance: 0.673 - \"Find recent blog posts or research papers on AI-powered code generation.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Find documentation for the latest version of Kubernetes.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.593 - \"Send me the latest changelog and release notes for your product.\"\n",
      "Distance: 0.623 - \"Get the most recent updates on AWS pricing changes.\"\n",
      "Distance: 0.652 - \"Generate a Kubernetes deployment YAML file for a Flask web application.\"\n",
      "Distance: 0.666 - \"Look up competitor product releases and announcements from the past month.\"\n",
      "Distance: 0.737 - \"Find recent blog posts or research papers on AI-powered code generation.\"\n",
      "Distance: 0.744 - \"Search for trending front-end frameworks in 2025 and compare their adoption rates.\"\n",
      "Distance: 0.758 - \"Search for recent tech layoffs and industry hiring trends.\"\n",
      "Distance: 0.782 - \"Provide a compatibility check—will your product work with my tech stack?\"\n",
      "Distance: 0.790 - \"List all employees who joined the company after January 1, 2023.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Find recent blog posts or research papers on AI-powered code generation.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.602 - \"Search for recent tech layoffs and industry hiring trends.\"\n",
      "Distance: 0.649 - \"Search for trending front-end frameworks in 2025 and compare their adoption rates.\"\n",
      "Distance: 0.673 - \"Look up competitor product releases and announcements from the past month.\"\n",
      "Distance: 0.711 - \"Generate a React component for a dynamic search bar with autocomplete.\"\n",
      "Distance: 0.732 - \"What training programs or career development resources are available?\"\n",
      "Distance: 0.734 - \"Find the best practices for optimizing large-scale database queries in PostgreSQL.\"\n",
      "Distance: 0.736 - \"Check if there are any regulatory changes affecting fintech apps in Europe.\"\n",
      "Distance: 0.737 - \"Find documentation for the latest version of Kubernetes.\"\n",
      "Distance: 0.741 - \"Look up salary benchmarks for software engineers in San Francisco.\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample a few random prompts and find their nearest neighbors\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "# Get embeddings for all training prompts\n",
    "all_embeddings = []\n",
    "all_prompts = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "    all_prompts.append(prompt)\n",
    "    \n",
    "all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "# Initialize KNN\n",
    "knn = NearestNeighbors(n_neighbors=10, metric=\"cosine\")  # 3 neighbors (including self)\n",
    "knn.fit(all_embeddings)\n",
    "\n",
    "# Sample 5 random prompts\n",
    "sample_indices = random.sample(range(len(all_prompts)), 5)\n",
    "\n",
    "print(\"Nearest neighbors analysis:\")\n",
    "print(\"-\" * 80)\n",
    "for idx in sample_indices:\n",
    "    query_embedding = all_embeddings[idx].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(query_embedding)\n",
    "    \n",
    "    print(f\"\\nQuery prompt: \\\"{all_prompts[idx]}\\\"\")\n",
    "    print(\"\\nNearest neighbors:\")\n",
    "    # Skip first neighbor (self) and show next 2\n",
    "    for d, i in zip(distances[0][1:], indices[0][1:]):\n",
    "        print(f\"Distance: {d:.3f} - \\\"{all_prompts[i]}\\\"\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241m.\u001b[39mkneighbors(query_embedding)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn' is not defined"
     ]
    }
   ],
   "source": [
    "distances, indices = knn.kneighbors(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample distances between points:\n",
      "[[0.        1.1991975 1.2099881 1.2253543 1.3701342 1.3525289 1.3651464\n",
      "  1.3733066 1.3476781 1.3160906]\n",
      " [1.1991975 0.        1.2105585 1.2254704 1.3729197 1.2827737 1.3788327\n",
      "  1.4081657 1.397967  1.3709254]\n",
      " [1.2099881 1.2105585 0.        1.2459263 1.2617028 1.2807477 1.3374196\n",
      "  1.3829098 1.2719167 1.3132303]\n",
      " [1.2253543 1.2254704 1.2459263 0.        1.351324  1.3308349 1.3988179\n",
      "  1.342134  1.3715174 1.3097007]\n",
      " [1.3701342 1.3729197 1.2617028 1.351324  0.        1.353681  1.3089576\n",
      "  1.2183383 1.2172592 1.306563 ]\n",
      " [1.3525289 1.2827737 1.2807477 1.3308349 1.353681  0.        1.3540425\n",
      "  1.3116673 1.3378683 1.3409972]\n",
      " [1.3651464 1.3788327 1.3374196 1.3988179 1.3089576 1.3540425 0.\n",
      "  1.3277911 1.2880034 1.2177488]\n",
      " [1.3733066 1.4081657 1.3829098 1.342134  1.2183383 1.3116673 1.3277911\n",
      "  0.        1.2655433 1.2194403]\n",
      " [1.3476781 1.397967  1.2719167 1.3715174 1.2172592 1.3378683 1.2880034\n",
      "  1.2655433 0.        1.3081747]\n",
      " [1.3160906 1.3709254 1.3132303 1.3097007 1.306563  1.3409972 1.2177488\n",
      "  1.2194403 1.3081747 0.       ]]\n",
      "\n",
      "Clustering threshold (min_samples * exp(alpha)): 26.560935381892378\n",
      "\n",
      "Distance statistics:\n",
      "Min distance: 0.873\n",
      "Max distance: 1.445\n",
      "Mean distance: 1.278\n",
      "Median distance: 1.296\n"
     ]
    }
   ],
   "source": [
    "# Let's explore why we don't have 1 cluster despite alpha < 0\n",
    "import numpy as np\n",
    "# 1. Print the actual distances between points to understand clustering behavior\n",
    "print(\"Sample distances between points:\")\n",
    "sample_embeddings = []\n",
    "sample_prompts = TRAIN_UPDATES[5:15]  # Take first 3 training examples\n",
    "for prompt, _ in sample_prompts:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    sample_embeddings.append(emb.numpy())\n",
    "\n",
    "sample_embeddings = np.array(sample_embeddings)\n",
    "distances = np.linalg.norm(sample_embeddings[:, None] - sample_embeddings, axis=2)\n",
    "print(distances)\n",
    "\n",
    "# 2. Print the actual clustering threshold being used\n",
    "print(f\"\\nClustering threshold (min_samples * exp(alpha)): {router.min_samples * np.exp(router.alpha)}\")\n",
    "\n",
    "# 3. Check the distribution of pairwise distances\n",
    "all_embeddings = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "    \n",
    "all_embeddings = np.array(all_embeddings)\n",
    "all_distances = np.linalg.norm(all_embeddings[:, None] - all_embeddings, axis=2)\n",
    "flat_distances = all_distances[np.triu_indices_from(all_distances, k=1)]\n",
    "\n",
    "print(f\"\\nDistance statistics:\")\n",
    "print(f\"Min distance: {np.min(flat_distances):.3f}\")\n",
    "print(f\"Max distance: {np.max(flat_distances):.3f}\")\n",
    "print(f\"Mean distance: {np.mean(flat_distances):.3f}\")\n",
    "print(f\"Median distance: {np.median(flat_distances):.3f}\")\n",
    "\n",
    "# This shows that even with alpha < 0, if the actual distances between points\n",
    "# are larger than the threshold, new clusters will still form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average intra-cluster cosine similarity: 0.270\n",
      "Average cross-cluster cosine similarity: 0.174\n"
     ]
    }
   ],
   "source": [
    "# Calculate average intra-cluster and cross-cluster distances using cosine similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get embeddings for all training prompts\n",
    "all_embeddings = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "# Split into 5 clusters of 10 prompts each\n",
    "clusters = []\n",
    "for i in range(0, 50, 10):\n",
    "    clusters.append(all_embeddings[i:i+10])\n",
    "\n",
    "# Calculate average intra-cluster similarities\n",
    "intra_cluster_sims = []\n",
    "for cluster in clusters:\n",
    "    # Get all pairwise similarities within cluster\n",
    "    sims = cosine_similarity(cluster)\n",
    "    # Get upper triangle only (excluding diagonal)\n",
    "    upper_tri = sims[np.triu_indices_from(sims, k=1)]\n",
    "    if len(upper_tri) > 0:\n",
    "        intra_cluster_sims.append(np.mean(upper_tri))\n",
    "\n",
    "avg_intra_sim = np.mean(intra_cluster_sims)\n",
    "print(f\"Average intra-cluster cosine similarity: {avg_intra_sim:.3f}\")\n",
    "\n",
    "# Calculate average cross-cluster similarities\n",
    "cross_cluster_sims = []\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i+1, len(clusters)):\n",
    "        sims = cosine_similarity(clusters[i], clusters[j])\n",
    "        cross_cluster_sims.append(np.mean(sims))\n",
    "\n",
    "avg_cross_sim = np.mean(cross_cluster_sims)\n",
    "print(f\"Average cross-cluster cosine similarity: {avg_cross_sim:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "  - Write a Dockerfile for a Node.js application with Express and PostgreSQL.\n",
      "  - Create a Terraform script to provision an AWS EC2 instance and configure security groups.\n",
      "  - Generate a Kubernetes deployment YAML file for a Flask web application.\n",
      "  - Find documentation for the latest version of Kubernetes.\n",
      "\n",
      "Cluster 1:\n",
      "  - Create a SQL query to retrieve the top 10 highest-paying customers from our database.\n",
      "  - Find the total number of employees working in the company and provide a breakdown by department.\n",
      "  - List all employees who joined the company after January 1, 2023.\n",
      "  - Get the email addresses of all team leads in the engineering department.\n",
      "  - Show me the employee with the highest salary in the company.\n",
      "  - Provide a list of employees along with their job titles and phone numbers.\n",
      "  - Fetch all employees who report to [Manager Name].\n",
      "  - Generate a list of employees whose work anniversary is this month.\n",
      "  - Find employees who have been with the company for more than five years.\n",
      "  - Retrieve a list of employees along with their assigned projects.\n",
      "\n",
      "Cluster 2:\n",
      "  - Get the most recent updates on AWS pricing changes.\n",
      "  - Search for trending front-end frameworks in 2025 and compare their adoption rates.\n",
      "  - Look up salary benchmarks for software engineers in San Francisco.\n",
      "  - Search for recent tech layoffs and industry hiring trends.\n",
      "  - Find the best practices for optimizing large-scale database queries in PostgreSQL.\n",
      "  - Check if there are any regulatory changes affecting fintech apps in Europe.\n",
      "  - Look up competitor product releases and announcements from the past month.\n",
      "  - Find recent blog posts or research papers on AI-powered code generation.\n",
      "  - I need to downgrade my subscription—what features will I lose?\n",
      "  - Provide a compatibility check—will your product work with my tech stack?\n",
      "  - Send me the latest changelog and release notes for your product.\n",
      "\n",
      "Cluster 3:\n",
      "  - Provide steps to integrate your API with my existing application.\n",
      "  - I'm experiencing latency issues with your cloud service—how can I fix this?\n",
      "  - Explain the security measures in place for protecting my account data.\n",
      "  - How do I set up multi-factor authentication for better security?\n",
      "\n",
      "Cluster 4:\n",
      "  - How do I request time off?\n",
      "  - Can you help me find my last three pay stubs?\n",
      "  - What is the process for filing a workplace complaint?\n",
      "  - How do I update my direct deposit information?\n",
      "  - Can you generate an employment verification letter for me?\n",
      "  - Can you help me migrate my data from another platform to your service?\n",
      "  - My software license key isn't working—how do I generate a new one?\n",
      "\n",
      "Cluster 5:\n",
      "  - Generate a Python script to automate file renaming in a directory based on a pattern.\n",
      "  - Write a Python script to scrape product prices from an e-commerce website and store them in a CSV file.\n",
      "\n",
      "Cluster 6:\n",
      "  - What are the company's healthcare benefits?\n",
      "  - What training programs or career development resources are available?\n",
      "  - Who do I contact for questions about my 401(k)?\n",
      "  - What is the company's remote work policy?\n",
      "\n",
      "Cluster 7:\n",
      "  - Write a function in JavaScript to validate email addresses using regex.\n",
      "  - Generate a React component for a dynamic search bar with autocomplete.\n",
      "  - Write a unit test suite in Jest for a function that processes user authentication.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Get embeddings for all training prompts\n",
    "train_embeddings = []\n",
    "train_prompts = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    train_embeddings.append(emb.numpy())\n",
    "    train_prompts.append(prompt)\n",
    "\n",
    "# Convert to numpy array\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "clusters = kmeans.fit_predict(train_embeddings)\n",
    "\n",
    "# Print prompts in each cluster\n",
    "for i in range(8):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    cluster_prompts = [prompt for j, prompt in enumerate(train_prompts) if clusters[j] == i]\n",
    "    for prompt in cluster_prompts:\n",
    "        print(f\"  - {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(router.clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "router",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
