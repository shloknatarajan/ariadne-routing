{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters formed after training update: 81\n",
      "\n",
      "Test Inference Results:\n",
      "Test Prompt 1: \"I have an issue with Workday. My hours weren't updated properly.\"\n",
      "Predicted Agent: HR Agent\n",
      "\n",
      "Test Prompt 2: \"Generate a Python script to fetch data from a REST API and store it in a database.\"\n",
      "Predicted Agent: Code Generation Agent\n",
      "\n",
      "Test Prompt 3: \"Find the latest security vulnerabilities in Python libraries we use.\"\n",
      "Predicted Agent: Web Search Agent\n",
      "\n",
      "Test Prompt 4: \"Help me troubleshoot why my SaaS account is locked.\"\n",
      "Predicted Agent: Customer Service Agent\n",
      "\n",
      "Test Prompt 5: \"Retrieve the contact details of all employees in the marketing department.\"\n",
      "Predicted Agent: Database Agent\n",
      "\n",
      "Test Prompt 6: \"Schedule a meeting with the engineering and marketing teams next Wednesday at 10 AM and send out invites.\"\n",
      "Predicted Agent: Executive Assistant Agent\n",
      "\n",
      "Test Prompt 7: \"Review the terms of service for our new SaaS product and ensure compliance with GDPR and CCPA.\"\n",
      "Predicted Agent: Legal Agent\n",
      "\n",
      "Test Prompt 8: \"Generate a set of test cases for the login functionality, including valid, invalid, and edge cases.\"\n",
      "Predicted Agent: Software QA Agent\n",
      "\n",
      "Test Prompt 9: \"Check my system's CPU and memory usage and report any high resource consumption.\"\n",
      "Predicted Agent: Web Automation Agent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stream_router import StreamRouter\n",
    "\n",
    "# Import training updates and test prompts from the external file.\n",
    "from ideation import TRAIN_UPDATES, TEST_PROMPTS\n",
    "\n",
    "router = StreamRouter([], embedding_dim=8, learning_rate=0.1, min_samples=12)\n",
    "\n",
    "for i in range(0, len(TRAIN_UPDATES), 9):\n",
    "    batch = TRAIN_UPDATES[i:i+9]\n",
    "    if batch:  # Only process if we have examples\n",
    "        agent = batch[0][1]  # Get agent name from first example\n",
    "        prompts = [p[0] for p in batch]  # Extract just the prompts\n",
    "        # print(agent, prompts)\n",
    "        router.add_agent(agent, prompts)\n",
    "\n",
    "for prompt, agent in TRAIN_UPDATES:\n",
    "    router.update(prompt, agent)\n",
    "print(f\"Total clusters formed after training update: {len(router.clusters)}\")\n",
    "\n",
    "# Debug: Print cluster details.\n",
    "# router.debug_clusters()\n",
    "\n",
    "# Execute test inferences using the imported test prompts.\n",
    "print(\"\\nTest Inference Results:\")\n",
    "for i, prompt in enumerate(TEST_PROMPTS, start=1):\n",
    "    predicted_agent = router.inference(prompt)\n",
    "    print(f\"Test Prompt {i}: \\\"{prompt}\\\"\")\n",
    "    print(f\"Predicted Agent: {predicted_agent}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router state saved successfully to router_state.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save essential components of the router\n",
    "router_state = {\n",
    "    'agents': router.agents,\n",
    "    'clusters': router.clusters,\n",
    "    'agent_embeddings': router.agent_embeddings,\n",
    "    'embedding_dim': router.embedding_dim,\n",
    "    'learning_rate': router.learning_rate,\n",
    "    'min_samples': router.min_samples,\n",
    "}\n",
    "\n",
    "with open('router_state_12.pkl', 'wb') as f:\n",
    "    pickle.dump(router_state, f)\n",
    "\n",
    "print(\"Router state saved successfully to router_state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster-Agent Embedding Similarities:\n",
      "--------------------------------------------------------------------------------\n",
      "Cluster 0 <-> HR Agent: 0.9869\n",
      "Cluster 1 <-> Code Generation Agent: 0.9348\n",
      "Cluster 2 <-> Web Search Agent: 0.9969\n",
      "Cluster 3 <-> Customer Service Agent: 0.9990\n",
      "Cluster 4 <-> Code Generation Agent: 0.9867\n",
      "Cluster 4 <-> Database Agent: 0.7033\n",
      "Cluster 5 <-> Executive Assistant Agent: 0.9994\n",
      "Cluster 6 <-> Legal Agent: 0.9951\n",
      "Cluster 7 <-> Software QA Agent: 0.9974\n",
      "Cluster 8 <-> Web Automation Agent: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# Measure cosine similarity between cluster embeddings and agent embeddings\n",
    "print(\"\\nCluster-Agent Embedding Similarities:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, cluster in enumerate(router.clusters):\n",
    "    if cluster[\"embedding\"] is not None:  # Only check clusters with learned embeddings\n",
    "        # Get all agents used in this cluster\n",
    "        agents_in_cluster = set(agent for _, agent in cluster[\"data\"])\n",
    "        \n",
    "        for agent in agents_in_cluster:\n",
    "            similarity = router._similarity(\n",
    "                cluster[\"embedding\"],\n",
    "                router.agent_embeddings[agent]\n",
    "            )\n",
    "            print(f\"Cluster {i} <-> {agent}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster-Agent Embedding Similarities:\n",
      "--------------------------------------------------------------------------------\n",
      "Cluster 0 <-> HR Agent: 0.9869\n",
      "Cluster 1 <-> Code Generation Agent: 0.9348\n",
      "Cluster 2 <-> Web Search Agent: 0.9969\n",
      "Cluster 3 <-> Customer Service Agent: 0.9990\n",
      "Cluster 4 <-> Code Generation Agent: 0.9867\n",
      "Cluster 4 <-> Database Agent: 0.7033\n",
      "Cluster 5 <-> Executive Assistant Agent: 0.9994\n",
      "Cluster 6 <-> Legal Agent: 0.9951\n",
      "Cluster 7 <-> Software QA Agent: 0.9974\n",
      "Cluster 8 <-> Web Automation Agent: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# Measure cosine similarity between cluster embeddings and agent embeddings\n",
    "print(\"\\nCluster-Agent Embedding Similarities:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, cluster in enumerate(router.clusters):\n",
    "    if cluster[\"embedding\"] is not None:  # Only check clusters with learned embeddings\n",
    "        # Get all agents used in this cluster\n",
    "        agents_in_cluster = set(agent for _, agent in cluster[\"data\"])\n",
    "        \n",
    "        for agent in agents_in_cluster:\n",
    "            similarity = router._similarity(\n",
    "                cluster[\"embedding\"],\n",
    "                router.agent_embeddings[agent]\n",
    "            )\n",
    "            print(f\"Cluster {i} <-> {agent}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors analysis:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Explain the security measures in place for protecting my account data.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.504 - \"How do I set up multi-factor authentication for better security?\"\n",
      "Distance: 0.610 - \"Identify possible security vulnerabilities and generate security test cases for user authentication.\"\n",
      "Distance: 0.639 - \"Backup all my important documents and pictures to an external drive.\"\n",
      "Distance: 0.680 - \"Generate a data privacy policy that aligns with global data protection regulations.\"\n",
      "Distance: 0.692 - \"Can you help me migrate my data from another platform to your service?\"\n",
      "Distance: 0.696 - \"Provide steps to integrate your API with my existing application.\"\n",
      "Distance: 0.722 - \"How do I update my direct deposit information?\"\n",
      "Distance: 0.725 - \"Draft a terms of service and privacy policy for a mobile app, ensuring compliance with App Store and Google Play guidelines.\"\n",
      "Distance: 0.737 - \"I'm experiencing latency issues with your cloud service—how can I fix this?\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Write a set of regression test cases to verify that recent updates did not break existing functionality.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.472 - \"Create test cases to verify responsiveness and cross-browser compatibility for the dashboard UI.\"\n",
      "Distance: 0.564 - \"Develop test cases for a file upload feature, including different file types and sizes.\"\n",
      "Distance: 0.572 - \"Generate a report summarizing test coverage for the latest software release.\"\n",
      "Distance: 0.587 - \"Generate test cases for API endpoint /getUserProfile, covering all possible response scenarios.\"\n",
      "Distance: 0.595 - \"Write automated test scripts for form validation on the user registration page.\"\n",
      "Distance: 0.596 - \"Identify possible security vulnerabilities and generate security test cases for user authentication.\"\n",
      "Distance: 0.600 - \"Write performance test scenarios to measure load handling for 10,000 concurrent users.\"\n",
      "Distance: 0.627 - \"Check if there are any regulatory changes affecting fintech apps in Europe.\"\n",
      "Distance: 0.630 - \"Write a unit test suite in Jest for a function that processes user authentication.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Find the total number of employees working in the company and provide a breakdown by department.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.495 - \"Provide a list of employees along with their job titles and phone numbers.\"\n",
      "Distance: 0.511 - \"Retrieve a list of employees along with their assigned projects.\"\n",
      "Distance: 0.522 - \"Fetch all employees who report to [Manager Name].\"\n",
      "Distance: 0.524 - \"Show me the employee with the highest salary in the company.\"\n",
      "Distance: 0.547 - \"Find employees who have been with the company for more than five years.\"\n",
      "Distance: 0.566 - \"Get the email addresses of all team leads in the engineering department.\"\n",
      "Distance: 0.567 - \"List all employees who joined the company after January 1, 2023.\"\n",
      "Distance: 0.582 - \"Generate a list of employees whose work anniversary is this month.\"\n",
      "Distance: 0.632 - \"Generate a report summarizing test coverage for the latest software release.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"What is the process for filing a workplace complaint?\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.638 - \"How do I request time off?\"\n",
      "Distance: 0.655 - \"Who do I contact for questions about my 401(k)?\"\n",
      "Distance: 0.695 - \"What is the company's remote work policy?\"\n",
      "Distance: 0.700 - \"Can you generate an employment verification letter for me?\"\n",
      "Distance: 0.705 - \"How do I update my direct deposit information?\"\n",
      "Distance: 0.737 - \"Generate a compliance checklist for software accessibility requirements under ADA and WCAG.\"\n",
      "Distance: 0.748 - \"Check my calendar for conflicts and suggest a better time for my one-on-one with [Employee].\"\n",
      "Distance: 0.755 - \"Draft an employee acceptable use policy (AUP) for company-issued laptops and software.\"\n",
      "Distance: 0.757 - \"Can you help me find my last three pay stubs?\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query prompt: \"Draft and send a follow-up email to [Client Name] thanking them for today's call and summarizing next steps.\"\n",
      "\n",
      "Nearest neighbors:\n",
      "Distance: 0.450 - \"Draft a professional email to [Vendor] requesting an updated contract before the end of the month.\"\n",
      "Distance: 0.609 - \"Reschedule my 3 PM meeting with [Person] to Friday at the same time and update the calendar invite.\"\n",
      "Distance: 0.609 - \"Set a reminder for me to review the quarterly financial report before Monday's executive meeting.\"\n",
      "Distance: 0.625 - \"Check my calendar for conflicts and suggest a better time for my one-on-one with [Employee].\"\n",
      "Distance: 0.643 - \"Create a daily agenda summary with my meetings, deadlines, and important tasks.\"\n",
      "Distance: 0.661 - \"Book a conference room for the product launch meeting next Tuesday at 2 PM.\"\n",
      "Distance: 0.673 - \"Summarize my unread emails and highlight anything urgent.\"\n",
      "Distance: 0.687 - \"Draft a non-disclosure agreement (NDA) for third-party contractors working on proprietary software.\"\n",
      "Distance: 0.691 - \"Provide a list of employees along with their job titles and phone numbers.\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample a few random prompts and find their nearest neighbors\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "# Get embeddings for all training prompts\n",
    "all_embeddings = []\n",
    "all_prompts = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "    all_prompts.append(prompt)\n",
    "    \n",
    "all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "# Initialize KNN\n",
    "knn = NearestNeighbors(n_neighbors=10, metric=\"cosine\")  # 3 neighbors (including self)\n",
    "knn.fit(all_embeddings)\n",
    "\n",
    "# Sample 5 random prompts\n",
    "sample_indices = random.sample(range(len(all_prompts)), 5)\n",
    "\n",
    "print(\"Nearest neighbors analysis:\")\n",
    "print(\"-\" * 80)\n",
    "for idx in sample_indices:\n",
    "    query_embedding = all_embeddings[idx].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(query_embedding)\n",
    "    \n",
    "    print(f\"\\nQuery prompt: \\\"{all_prompts[idx]}\\\"\")\n",
    "    print(\"\\nNearest neighbors:\")\n",
    "    # Skip first neighbor (self) and show next 2\n",
    "    for d, i in zip(distances[0][1:], indices[0][1:]):\n",
    "        print(f\"Distance: {d:.3f} - \\\"{all_prompts[i]}\\\"\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241m.\u001b[39mkneighbors(query_embedding)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn' is not defined"
     ]
    }
   ],
   "source": [
    "distances, indices = knn.kneighbors(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample distances between points:\n",
      "[[0.        1.1991975 1.2099881 1.2253543 1.3701342 1.3525289 1.3651464\n",
      "  1.3733066 1.3476781 1.3160906]\n",
      " [1.1991975 0.        1.2105585 1.2254704 1.3729197 1.2827737 1.3788327\n",
      "  1.4081657 1.397967  1.3709254]\n",
      " [1.2099881 1.2105585 0.        1.2459263 1.2617028 1.2807477 1.3374196\n",
      "  1.3829098 1.2719167 1.3132303]\n",
      " [1.2253543 1.2254704 1.2459263 0.        1.351324  1.3308349 1.3988179\n",
      "  1.342134  1.3715174 1.3097007]\n",
      " [1.3701342 1.3729197 1.2617028 1.351324  0.        1.353681  1.3089576\n",
      "  1.2183383 1.2172592 1.306563 ]\n",
      " [1.3525289 1.2827737 1.2807477 1.3308349 1.353681  0.        1.3540425\n",
      "  1.3116673 1.3378683 1.3409972]\n",
      " [1.3651464 1.3788327 1.3374196 1.3988179 1.3089576 1.3540425 0.\n",
      "  1.3277911 1.2880034 1.2177488]\n",
      " [1.3733066 1.4081657 1.3829098 1.342134  1.2183383 1.3116673 1.3277911\n",
      "  0.        1.2655433 1.2194403]\n",
      " [1.3476781 1.397967  1.2719167 1.3715174 1.2172592 1.3378683 1.2880034\n",
      "  1.2655433 0.        1.3081747]\n",
      " [1.3160906 1.3709254 1.3132303 1.3097007 1.306563  1.3409972 1.2177488\n",
      "  1.2194403 1.3081747 0.       ]]\n",
      "\n",
      "Clustering threshold (min_samples * exp(alpha)): 26.560935381892378\n",
      "\n",
      "Distance statistics:\n",
      "Min distance: 0.873\n",
      "Max distance: 1.445\n",
      "Mean distance: 1.278\n",
      "Median distance: 1.296\n"
     ]
    }
   ],
   "source": [
    "# Let's explore why we don't have 1 cluster despite alpha < 0\n",
    "import numpy as np\n",
    "# 1. Print the actual distances between points to understand clustering behavior\n",
    "print(\"Sample distances between points:\")\n",
    "sample_embeddings = []\n",
    "sample_prompts = TRAIN_UPDATES[5:15]  # Take first 3 training examples\n",
    "for prompt, _ in sample_prompts:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    sample_embeddings.append(emb.numpy())\n",
    "\n",
    "sample_embeddings = np.array(sample_embeddings)\n",
    "distances = np.linalg.norm(sample_embeddings[:, None] - sample_embeddings, axis=2)\n",
    "print(distances)\n",
    "\n",
    "# 2. Print the actual clustering threshold being used\n",
    "print(f\"\\nClustering threshold (min_samples * exp(alpha)): {router.min_samples * np.exp(router.alpha)}\")\n",
    "\n",
    "# 3. Check the distribution of pairwise distances\n",
    "all_embeddings = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "    \n",
    "all_embeddings = np.array(all_embeddings)\n",
    "all_distances = np.linalg.norm(all_embeddings[:, None] - all_embeddings, axis=2)\n",
    "flat_distances = all_distances[np.triu_indices_from(all_distances, k=1)]\n",
    "\n",
    "print(f\"\\nDistance statistics:\")\n",
    "print(f\"Min distance: {np.min(flat_distances):.3f}\")\n",
    "print(f\"Max distance: {np.max(flat_distances):.3f}\")\n",
    "print(f\"Mean distance: {np.mean(flat_distances):.3f}\")\n",
    "print(f\"Median distance: {np.median(flat_distances):.3f}\")\n",
    "\n",
    "# This shows that even with alpha < 0, if the actual distances between points\n",
    "# are larger than the threshold, new clusters will still form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average intra-cluster cosine similarity: 0.270\n",
      "Average cross-cluster cosine similarity: 0.174\n"
     ]
    }
   ],
   "source": [
    "# Calculate average intra-cluster and cross-cluster distances using cosine similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get embeddings for all training prompts\n",
    "all_embeddings = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    all_embeddings.append(emb.numpy())\n",
    "all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "# Split into 5 clusters of 10 prompts each\n",
    "clusters = []\n",
    "for i in range(0, 50, 10):\n",
    "    clusters.append(all_embeddings[i:i+10])\n",
    "\n",
    "# Calculate average intra-cluster similarities\n",
    "intra_cluster_sims = []\n",
    "for cluster in clusters:\n",
    "    # Get all pairwise similarities within cluster\n",
    "    sims = cosine_similarity(cluster)\n",
    "    # Get upper triangle only (excluding diagonal)\n",
    "    upper_tri = sims[np.triu_indices_from(sims, k=1)]\n",
    "    if len(upper_tri) > 0:\n",
    "        intra_cluster_sims.append(np.mean(upper_tri))\n",
    "\n",
    "avg_intra_sim = np.mean(intra_cluster_sims)\n",
    "print(f\"Average intra-cluster cosine similarity: {avg_intra_sim:.3f}\")\n",
    "\n",
    "# Calculate average cross-cluster similarities\n",
    "cross_cluster_sims = []\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i+1, len(clusters)):\n",
    "        sims = cosine_similarity(clusters[i], clusters[j])\n",
    "        cross_cluster_sims.append(np.mean(sims))\n",
    "\n",
    "avg_cross_sim = np.mean(cross_cluster_sims)\n",
    "print(f\"Average cross-cluster cosine similarity: {avg_cross_sim:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "  - Write a Dockerfile for a Node.js application with Express and PostgreSQL.\n",
      "  - Create a Terraform script to provision an AWS EC2 instance and configure security groups.\n",
      "  - Generate a Kubernetes deployment YAML file for a Flask web application.\n",
      "  - Find documentation for the latest version of Kubernetes.\n",
      "\n",
      "Cluster 1:\n",
      "  - Create a SQL query to retrieve the top 10 highest-paying customers from our database.\n",
      "  - Find the total number of employees working in the company and provide a breakdown by department.\n",
      "  - List all employees who joined the company after January 1, 2023.\n",
      "  - Get the email addresses of all team leads in the engineering department.\n",
      "  - Show me the employee with the highest salary in the company.\n",
      "  - Provide a list of employees along with their job titles and phone numbers.\n",
      "  - Fetch all employees who report to [Manager Name].\n",
      "  - Generate a list of employees whose work anniversary is this month.\n",
      "  - Find employees who have been with the company for more than five years.\n",
      "  - Retrieve a list of employees along with their assigned projects.\n",
      "\n",
      "Cluster 2:\n",
      "  - Get the most recent updates on AWS pricing changes.\n",
      "  - Search for trending front-end frameworks in 2025 and compare their adoption rates.\n",
      "  - Look up salary benchmarks for software engineers in San Francisco.\n",
      "  - Search for recent tech layoffs and industry hiring trends.\n",
      "  - Find the best practices for optimizing large-scale database queries in PostgreSQL.\n",
      "  - Check if there are any regulatory changes affecting fintech apps in Europe.\n",
      "  - Look up competitor product releases and announcements from the past month.\n",
      "  - Find recent blog posts or research papers on AI-powered code generation.\n",
      "  - I need to downgrade my subscription—what features will I lose?\n",
      "  - Provide a compatibility check—will your product work with my tech stack?\n",
      "  - Send me the latest changelog and release notes for your product.\n",
      "\n",
      "Cluster 3:\n",
      "  - Provide steps to integrate your API with my existing application.\n",
      "  - I'm experiencing latency issues with your cloud service—how can I fix this?\n",
      "  - Explain the security measures in place for protecting my account data.\n",
      "  - How do I set up multi-factor authentication for better security?\n",
      "\n",
      "Cluster 4:\n",
      "  - How do I request time off?\n",
      "  - Can you help me find my last three pay stubs?\n",
      "  - What is the process for filing a workplace complaint?\n",
      "  - How do I update my direct deposit information?\n",
      "  - Can you generate an employment verification letter for me?\n",
      "  - Can you help me migrate my data from another platform to your service?\n",
      "  - My software license key isn't working—how do I generate a new one?\n",
      "\n",
      "Cluster 5:\n",
      "  - Generate a Python script to automate file renaming in a directory based on a pattern.\n",
      "  - Write a Python script to scrape product prices from an e-commerce website and store them in a CSV file.\n",
      "\n",
      "Cluster 6:\n",
      "  - What are the company's healthcare benefits?\n",
      "  - What training programs or career development resources are available?\n",
      "  - Who do I contact for questions about my 401(k)?\n",
      "  - What is the company's remote work policy?\n",
      "\n",
      "Cluster 7:\n",
      "  - Write a function in JavaScript to validate email addresses using regex.\n",
      "  - Generate a React component for a dynamic search bar with autocomplete.\n",
      "  - Write a unit test suite in Jest for a function that processes user authentication.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Get embeddings for all training prompts\n",
    "train_embeddings = []\n",
    "train_prompts = []\n",
    "for prompt, _ in TRAIN_UPDATES:\n",
    "    emb = router._compute_prompt_embedding(prompt)\n",
    "    train_embeddings.append(emb.numpy())\n",
    "    train_prompts.append(prompt)\n",
    "\n",
    "# Convert to numpy array\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "clusters = kmeans.fit_predict(train_embeddings)\n",
    "\n",
    "# Print prompts in each cluster\n",
    "for i in range(8):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    cluster_prompts = [prompt for j, prompt in enumerate(train_prompts) if clusters[j] == i]\n",
    "    for prompt in cluster_prompts:\n",
    "        print(f\"  - {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(router.clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariadne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
