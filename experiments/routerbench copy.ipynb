{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/5cczn_jx4454n6fvhcg5qbjw0000gn/T/ipykernel_44549/1371555631.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  routerbench_data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Open and load the routerbench_5shot.pkl file\n",
    "with open('routerbench_5shot.pkl', 'rb') as f:\n",
    "    routerbench_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configure pandas to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinese_character_riddles', 'abstract2title', 'accounting_audit',\n",
       "       'arc-challenge', 'bias_detection', 'chinese-lantern-riddles',\n",
       "       'chinese-remainder-theorem',\n",
       "       'chinese_ancient_masterpieces_dynasty', 'chinese_ancient_poetry',\n",
       "       'chinese_chu_ci', 'chinese_famous_novel',\n",
       "       'chinese_hard_translations', 'chinese_homonym', 'chinese_idioms',\n",
       "       'chinese_modern_poem_identification', 'chinese_poem',\n",
       "       'chinese_shi_jing', 'chinese_song_ci', 'chinese_tang_poetries',\n",
       "       'chinese_zodiac', 'consensus_summary', 'grade-school-math',\n",
       "       'hellaswag', 'mbpp', 'mmlu-abstract-algebra', 'mmlu-anatomy',\n",
       "       'mmlu-astronomy', 'mmlu-business-ethics',\n",
       "       'mmlu-clinical-knowledge', 'mmlu-college-biology',\n",
       "       'mmlu-college-chemistry', 'mmlu-college-computer-science',\n",
       "       'mmlu-college-mathematics', 'mmlu-college-medicine',\n",
       "       'mmlu-college-physics', 'mmlu-computer-security',\n",
       "       'mmlu-conceptual-physics', 'mmlu-econometrics',\n",
       "       'mmlu-electrical-engineering', 'mmlu-elementary-mathematics',\n",
       "       'mmlu-formal-logic', 'mmlu-global-facts',\n",
       "       'mmlu-high-school-biology', 'mmlu-high-school-chemistry',\n",
       "       'mmlu-high-school-computer-science',\n",
       "       'mmlu-high-school-european-history', 'mmlu-high-school-geography',\n",
       "       'mmlu-high-school-government-and-politics',\n",
       "       'mmlu-high-school-macroeconomics', 'mmlu-high-school-mathematics',\n",
       "       'mmlu-high-school-microeconomics', 'mmlu-high-school-physics',\n",
       "       'mmlu-high-school-psychology', 'mmlu-high-school-statistics',\n",
       "       'mmlu-high-school-us-history', 'mmlu-high-school-world-history',\n",
       "       'mmlu-human-aging', 'mmlu-human-sexuality',\n",
       "       'mmlu-international-law', 'mmlu-jurisprudence',\n",
       "       'mmlu-logical-fallacies', 'mmlu-machine-learning',\n",
       "       'mmlu-management', 'mmlu-marketing', 'mmlu-medical-genetics',\n",
       "       'mmlu-miscellaneous', 'mmlu-moral-disputes',\n",
       "       'mmlu-moral-scenarios', 'mmlu-nutrition', 'mmlu-philosophy',\n",
       "       'mmlu-prehistory', 'mmlu-professional-accounting',\n",
       "       'mmlu-professional-law', 'mmlu-professional-medicine',\n",
       "       'mmlu-professional-psychology', 'mmlu-public-relations',\n",
       "       'mmlu-security-studies', 'mmlu-sociology',\n",
       "       'mmlu-us-foreign-policy', 'mmlu-virology', 'mmlu-world-religions',\n",
       "       'mtbench-math', 'mtbench-reference', 'mtbench', 'test-match',\n",
       "       'winogrande'], dtype=object)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routerbench_data['eval_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>eval_name</th>\n",
       "      <th>WizardLM/WizardLM-13B-V1.2</th>\n",
       "      <th>claude-instant-v1</th>\n",
       "      <th>claude-v1</th>\n",
       "      <th>claude-v2</th>\n",
       "      <th>gpt-3.5-turbo-1106</th>\n",
       "      <th>gpt-4-1106-preview</th>\n",
       "      <th>meta/code-llama-instruct-34b-chat</th>\n",
       "      <th>meta/llama-2-70b-chat</th>\n",
       "      <th>mistralai/mistral-7b-chat</th>\n",
       "      <th>mistralai/mixtral-8x7b-chat</th>\n",
       "      <th>zero-one-ai/Yi-34B-Chat</th>\n",
       "      <th>gpt-3.5-turbo-1106|model_response</th>\n",
       "      <th>claude-instant-v1|model_response</th>\n",
       "      <th>claude-v1|model_response</th>\n",
       "      <th>claude-v2|model_response</th>\n",
       "      <th>gpt-4-1106-preview|model_response</th>\n",
       "      <th>meta/llama-2-70b-chat|model_response</th>\n",
       "      <th>mistralai/mixtral-8x7b-chat|model_response</th>\n",
       "      <th>zero-one-ai/Yi-34B-Chat|model_response</th>\n",
       "      <th>WizardLM/WizardLM-13B-V1.2|model_response</th>\n",
       "      <th>meta/code-llama-instruct-34b-chat|model_response</th>\n",
       "      <th>mistralai/mistral-7b-chat|model_response</th>\n",
       "      <th>gpt-3.5-turbo-1106|total_cost</th>\n",
       "      <th>claude-instant-v1|total_cost</th>\n",
       "      <th>claude-v1|total_cost</th>\n",
       "      <th>claude-v2|total_cost</th>\n",
       "      <th>gpt-4-1106-preview|total_cost</th>\n",
       "      <th>meta/llama-2-70b-chat|total_cost</th>\n",
       "      <th>mistralai/mixtral-8x7b-chat|total_cost</th>\n",
       "      <th>zero-one-ai/Yi-34B-Chat|total_cost</th>\n",
       "      <th>WizardLM/WizardLM-13B-V1.2|total_cost</th>\n",
       "      <th>meta/code-llama-instruct-34b-chat|total_cost</th>\n",
       "      <th>mistralai/mistral-7b-chat|total_cost</th>\n",
       "      <th>oracle_model_to_route_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20692</th>\n",
       "      <td>mbpp.dev.0</td>\n",
       "      <td>['Write a function to find the shared elements...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Here's a Python function to find the shared ...</td>\n",
       "      <td>['Here is a function to find the shared elemen...</td>\n",
       "      <td>['Here is a function to find the shared elemen...</td>\n",
       "      <td>['Here is a Python function to find the shared...</td>\n",
       "      <td>['Certainly! Below is a Python function that t...</td>\n",
       "      <td>[' Sure! Here\\'s a function that finds the sha...</td>\n",
       "      <td>[\"Sure, here is a simple function in Python th...</td>\n",
       "      <td>[\"\\n```python\\ndef find_shared_elements(list1,...</td>\n",
       "      <td>[\"Here's a Python function that finds the shar...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef find_shared_elements(list1,...</td>\n",
       "      <td>['Here is a function written in Python that ca...</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>mistralai/mistral-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20693</th>\n",
       "      <td>mbpp.dev.1</td>\n",
       "      <td>['Write a python function to identify non-prim...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Here\\'s a Python function to identify non-pr...</td>\n",
       "      <td>['Here is a Python function to identify non-pr...</td>\n",
       "      <td>['Here is a Python function to identify non-pr...</td>\n",
       "      <td>['Here is a python function to identify non-pr...</td>\n",
       "      <td>['Here\\'s a Python function that identifies no...</td>\n",
       "      <td>[\" Sure! Here's a simple function that takes a...</td>\n",
       "      <td>['Sure, here is a simple Python function that ...</td>\n",
       "      <td>[\"\\nHere's a simple Python function that takes...</td>\n",
       "      <td>[\"Here's a simple Python function that identif...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef is_prime(n):\\n    if n &lt;= 1...</td>\n",
       "      <td>['Here is a simple Python function that identi...</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.01091</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>mistralai/mistral-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20694</th>\n",
       "      <td>mbpp.dev.10</td>\n",
       "      <td>['Write a function to that returns true if the...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Here\\'s a function in Python that checks for...</td>\n",
       "      <td>['def check_string(input_string):\\n    if \"_\" ...</td>\n",
       "      <td>[\"Here is a function that returns true if the ...</td>\n",
       "      <td>['Here is a Python function that returns true ...</td>\n",
       "      <td>['Certainly! Below is a Python function that c...</td>\n",
       "      <td>[' Sure! Here\\'s a possible implementation of ...</td>\n",
       "      <td>['Here is a function in Python that checks if ...</td>\n",
       "      <td>['\\nHere\\'s a Python function that does this:\\...</td>\n",
       "      <td>[\"Here's a Python function that checks if a gi...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef check_underscore_sequence(i...</td>\n",
       "      <td>[\"Here is a function in Python that checks if ...</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.01026</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>no_model_correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20695</th>\n",
       "      <td>mbpp.dev.100</td>\n",
       "      <td>['Write a function to find the sum of numbers ...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Here\\'s a Python function to find the sum of...</td>\n",
       "      <td>['Here is a function to find the sum of number...</td>\n",
       "      <td>['Here is a function that finds the sum of num...</td>\n",
       "      <td>['Here is a Python function to find the sum of...</td>\n",
       "      <td>['Certainly! Below is a Python function that t...</td>\n",
       "      <td>[\" Sure! Here's a function that takes a list o...</td>\n",
       "      <td>['Sure, here is a Python function that does th...</td>\n",
       "      <td>['\\n```python\\ndef sum_range(lst, start, end):...</td>\n",
       "      <td>[\"Here's a Python function that takes a list o...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef sum_range(my_list, start, e...</td>\n",
       "      <td>['Here is a function written in Python that ta...</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.01241</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>mistralai/mistral-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20696</th>\n",
       "      <td>mbpp.dev.101</td>\n",
       "      <td>['Write a function to find the perimeter of a ...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['You can use the following Python function to...</td>\n",
       "      <td>['Here is a function to calculate the perimete...</td>\n",
       "      <td>['Here is a function to find the perimeter of ...</td>\n",
       "      <td>['Here is the function to find the perimeter o...</td>\n",
       "      <td>['To find the perimeter of a regular pentagon,...</td>\n",
       "      <td>[\" Sure! Here's a function that takes the leng...</td>\n",
       "      <td>['Sure, here is a simple function in Python to...</td>\n",
       "      <td>['\\nHere\\'s a Python function that calculates ...</td>\n",
       "      <td>['To find the perimeter of a regular pentagon,...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef get_perimeter(side_length):...</td>\n",
       "      <td>['Here is a Python function that calculates th...</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.00649</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>mistralai/mixtral-8x7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21114</th>\n",
       "      <td>mbpp.dev.95</td>\n",
       "      <td>['Write a function to determine if the sum of ...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Here's a Python function to determine if the...</td>\n",
       "      <td>['def same_divisor_sum(a, b):\\n    divisor_sum...</td>\n",
       "      <td>['Here is a function that determines if the su...</td>\n",
       "      <td>['Here is a function to determine if the sum o...</td>\n",
       "      <td>['Here\\'s a Python function that determines if...</td>\n",
       "      <td>[\" Here's a possible implementation of a funct...</td>\n",
       "      <td>['To determine if the sum of the divisors of t...</td>\n",
       "      <td>['\\nCertainly! Below is a Python function that...</td>\n",
       "      <td>[\"Here's a Python function that takes two inte...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef same_sum_divisors(n1, n2):\\...</td>\n",
       "      <td>['Here is a function in Python that can determ...</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.01354</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>meta/code-llama-instruct-34b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21115</th>\n",
       "      <td>mbpp.dev.96</td>\n",
       "      <td>['Write a function to count the number of char...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Here\\'s a Python function to count the numbe...</td>\n",
       "      <td>['def count_alphabet_chars(string):\\n    count...</td>\n",
       "      <td>[\"Here is a function that counts the number of...</td>\n",
       "      <td>['Here is the function to count the number of ...</td>\n",
       "      <td>['Here\\'s a Python function that counts the nu...</td>\n",
       "      <td>[' Here\\'s a possible implementation of such a...</td>\n",
       "      <td>['Here is a Python function that counts the nu...</td>\n",
       "      <td>['\\nFor example, if the string is \"Hello World...</td>\n",
       "      <td>['Here\\'s a Python function that counts the nu...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef count_common_chars(my_strin...</td>\n",
       "      <td>[\"Here is a function in Python that counts the...</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.01110</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21116</th>\n",
       "      <td>mbpp.dev.97</td>\n",
       "      <td>['Write a function that counts the number of p...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Here's a Python function that counts the num...</td>\n",
       "      <td>['Here is a solution:\\n```python\\ndef count_ev...</td>\n",
       "      <td>[\"Here is a function that counts the number of...</td>\n",
       "      <td>['Here is a Python function to count the numbe...</td>\n",
       "      <td>['To count the number of pairs of integers in ...</td>\n",
       "      <td>[\" Sure! Here's a possible implementation of s...</td>\n",
       "      <td>['Here is a Python function that counts the nu...</td>\n",
       "      <td>[\"\\nTo solve this problem, we can use a list c...</td>\n",
       "      <td>[\"Here's a Python function that counts the num...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef count_pairs(my_list):\\n    ...</td>\n",
       "      <td>['Here is a Python function that counts the nu...</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.01287</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>mistralai/mistral-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21117</th>\n",
       "      <td>mbpp.dev.98</td>\n",
       "      <td>['Write a python function to find the smallest...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['```python\\ndef smallest_power_of_2(n):\\n    ...</td>\n",
       "      <td>['Here is a python function to find the smalle...</td>\n",
       "      <td>[\"Here's a Python function to find the smalles...</td>\n",
       "      <td>['Here is the python function to find the smal...</td>\n",
       "      <td>['To find the smallest power of 2 greater than...</td>\n",
       "      <td>[\" Sure! Here's a Python function that finds t...</td>\n",
       "      <td>['Here is a Python function that finds the sma...</td>\n",
       "      <td>[\"\\nHere's a Python function that finds the sm...</td>\n",
       "      <td>['Here\\'s a Python function that finds the sma...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef get_power_of_2(n):\\n    pow...</td>\n",
       "      <td>['Here is a simple python function that finds ...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.00868</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>WizardLM/WizardLM-13B-V1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21118</th>\n",
       "      <td>mbpp.dev.99</td>\n",
       "      <td>['Write a function to count the number of occu...</td>\n",
       "      <td>mbpp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"Here's a Python function to count the number...</td>\n",
       "      <td>['Here is a function to count the number of oc...</td>\n",
       "      <td>['Here is a function to count the occurrences ...</td>\n",
       "      <td>['Here is a Python function to count the numbe...</td>\n",
       "      <td>['Certainly! Below is a Python function that c...</td>\n",
       "      <td>[\" Sure! Here's a function that counts the num...</td>\n",
       "      <td>[\"Here is a simple function in Python that cou...</td>\n",
       "      <td>[\"\\nHere's a Python function that counts the n...</td>\n",
       "      <td>[\"Here's a Python function that takes a list a...</td>\n",
       "      <td>[' \\n[PYTHON]\\ndef count_occurrences(my_list, ...</td>\n",
       "      <td>['Here is a function written in Python that co...</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>mistralai/mistral-7b-chat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sample_id                                             prompt  \\\n",
       "20692    mbpp.dev.0  ['Write a function to find the shared elements...   \n",
       "20693    mbpp.dev.1  ['Write a python function to identify non-prim...   \n",
       "20694   mbpp.dev.10  ['Write a function to that returns true if the...   \n",
       "20695  mbpp.dev.100  ['Write a function to find the sum of numbers ...   \n",
       "20696  mbpp.dev.101  ['Write a function to find the perimeter of a ...   \n",
       "...             ...                                                ...   \n",
       "21114   mbpp.dev.95  ['Write a function to determine if the sum of ...   \n",
       "21115   mbpp.dev.96  ['Write a function to count the number of char...   \n",
       "21116   mbpp.dev.97  ['Write a function that counts the number of p...   \n",
       "21117   mbpp.dev.98  ['Write a python function to find the smallest...   \n",
       "21118   mbpp.dev.99  ['Write a function to count the number of occu...   \n",
       "\n",
       "      eval_name WizardLM/WizardLM-13B-V1.2 claude-instant-v1 claude-v1  \\\n",
       "20692      mbpp                        1.0               1.0       1.0   \n",
       "20693      mbpp                        1.0               1.0       1.0   \n",
       "20694      mbpp                        0.0               0.0       0.0   \n",
       "20695      mbpp                        0.0               1.0       1.0   \n",
       "20696      mbpp                        1.0               1.0       1.0   \n",
       "...         ...                        ...               ...       ...   \n",
       "21114      mbpp                        0.0               1.0       1.0   \n",
       "21115      mbpp                        0.0               1.0       1.0   \n",
       "21116      mbpp                        0.0               1.0       0.0   \n",
       "21117      mbpp                        1.0               1.0       1.0   \n",
       "21118      mbpp                        1.0               1.0       1.0   \n",
       "\n",
       "      claude-v2 gpt-3.5-turbo-1106 gpt-4-1106-preview  \\\n",
       "20692       1.0                1.0                1.0   \n",
       "20693       1.0                1.0                0.0   \n",
       "20694       0.0                0.0                0.0   \n",
       "20695       1.0                1.0                1.0   \n",
       "20696       1.0                1.0                1.0   \n",
       "...         ...                ...                ...   \n",
       "21114       0.0                1.0                1.0   \n",
       "21115       1.0                1.0                1.0   \n",
       "21116       1.0                1.0                1.0   \n",
       "21117       0.0                1.0                1.0   \n",
       "21118       1.0                1.0                1.0   \n",
       "\n",
       "      meta/code-llama-instruct-34b-chat meta/llama-2-70b-chat  \\\n",
       "20692                               1.0                   1.0   \n",
       "20693                               0.0                   1.0   \n",
       "20694                               0.0                   0.0   \n",
       "20695                               1.0                   0.0   \n",
       "20696                               1.0                   0.0   \n",
       "...                                 ...                   ...   \n",
       "21114                               1.0                   0.0   \n",
       "21115                               0.0                   0.0   \n",
       "21116                               0.0                   0.0   \n",
       "21117                               1.0                   0.0   \n",
       "21118                               1.0                   1.0   \n",
       "\n",
       "      mistralai/mistral-7b-chat mistralai/mixtral-8x7b-chat  \\\n",
       "20692                       1.0                         0.0   \n",
       "20693                       1.0                         0.0   \n",
       "20694                       0.0                         0.0   \n",
       "20695                       1.0                         1.0   \n",
       "20696                       0.0                         1.0   \n",
       "...                         ...                         ...   \n",
       "21114                       0.0                         0.0   \n",
       "21115                       0.0                         0.0   \n",
       "21116                       1.0                         1.0   \n",
       "21117                       0.0                         0.0   \n",
       "21118                       1.0                         1.0   \n",
       "\n",
       "      zero-one-ai/Yi-34B-Chat  \\\n",
       "20692                     1.0   \n",
       "20693                     1.0   \n",
       "20694                     0.0   \n",
       "20695                     0.0   \n",
       "20696                     1.0   \n",
       "...                       ...   \n",
       "21114                     1.0   \n",
       "21115                     0.0   \n",
       "21116                     1.0   \n",
       "21117                     1.0   \n",
       "21118                     1.0   \n",
       "\n",
       "                       gpt-3.5-turbo-1106|model_response  \\\n",
       "20692  [\"Here's a Python function to find the shared ...   \n",
       "20693  ['Here\\'s a Python function to identify non-pr...   \n",
       "20694  ['Here\\'s a function in Python that checks for...   \n",
       "20695  ['Here\\'s a Python function to find the sum of...   \n",
       "20696  ['You can use the following Python function to...   \n",
       "...                                                  ...   \n",
       "21114  [\"Here's a Python function to determine if the...   \n",
       "21115  ['Here\\'s a Python function to count the numbe...   \n",
       "21116  [\"Here's a Python function that counts the num...   \n",
       "21117  ['```python\\ndef smallest_power_of_2(n):\\n    ...   \n",
       "21118  [\"Here's a Python function to count the number...   \n",
       "\n",
       "                        claude-instant-v1|model_response  \\\n",
       "20692  ['Here is a function to find the shared elemen...   \n",
       "20693  ['Here is a Python function to identify non-pr...   \n",
       "20694  ['def check_string(input_string):\\n    if \"_\" ...   \n",
       "20695  ['Here is a function to find the sum of number...   \n",
       "20696  ['Here is a function to calculate the perimete...   \n",
       "...                                                  ...   \n",
       "21114  ['def same_divisor_sum(a, b):\\n    divisor_sum...   \n",
       "21115  ['def count_alphabet_chars(string):\\n    count...   \n",
       "21116  ['Here is a solution:\\n```python\\ndef count_ev...   \n",
       "21117  ['Here is a python function to find the smalle...   \n",
       "21118  ['Here is a function to count the number of oc...   \n",
       "\n",
       "                                claude-v1|model_response  \\\n",
       "20692  ['Here is a function to find the shared elemen...   \n",
       "20693  ['Here is a Python function to identify non-pr...   \n",
       "20694  [\"Here is a function that returns true if the ...   \n",
       "20695  ['Here is a function that finds the sum of num...   \n",
       "20696  ['Here is a function to find the perimeter of ...   \n",
       "...                                                  ...   \n",
       "21114  ['Here is a function that determines if the su...   \n",
       "21115  [\"Here is a function that counts the number of...   \n",
       "21116  [\"Here is a function that counts the number of...   \n",
       "21117  [\"Here's a Python function to find the smalles...   \n",
       "21118  ['Here is a function to count the occurrences ...   \n",
       "\n",
       "                                claude-v2|model_response  \\\n",
       "20692  ['Here is a Python function to find the shared...   \n",
       "20693  ['Here is a python function to identify non-pr...   \n",
       "20694  ['Here is a Python function that returns true ...   \n",
       "20695  ['Here is a Python function to find the sum of...   \n",
       "20696  ['Here is the function to find the perimeter o...   \n",
       "...                                                  ...   \n",
       "21114  ['Here is a function to determine if the sum o...   \n",
       "21115  ['Here is the function to count the number of ...   \n",
       "21116  ['Here is a Python function to count the numbe...   \n",
       "21117  ['Here is the python function to find the smal...   \n",
       "21118  ['Here is a Python function to count the numbe...   \n",
       "\n",
       "                       gpt-4-1106-preview|model_response  \\\n",
       "20692  ['Certainly! Below is a Python function that t...   \n",
       "20693  ['Here\\'s a Python function that identifies no...   \n",
       "20694  ['Certainly! Below is a Python function that c...   \n",
       "20695  ['Certainly! Below is a Python function that t...   \n",
       "20696  ['To find the perimeter of a regular pentagon,...   \n",
       "...                                                  ...   \n",
       "21114  ['Here\\'s a Python function that determines if...   \n",
       "21115  ['Here\\'s a Python function that counts the nu...   \n",
       "21116  ['To count the number of pairs of integers in ...   \n",
       "21117  ['To find the smallest power of 2 greater than...   \n",
       "21118  ['Certainly! Below is a Python function that c...   \n",
       "\n",
       "                    meta/llama-2-70b-chat|model_response  \\\n",
       "20692  [' Sure! Here\\'s a function that finds the sha...   \n",
       "20693  [\" Sure! Here's a simple function that takes a...   \n",
       "20694  [' Sure! Here\\'s a possible implementation of ...   \n",
       "20695  [\" Sure! Here's a function that takes a list o...   \n",
       "20696  [\" Sure! Here's a function that takes the leng...   \n",
       "...                                                  ...   \n",
       "21114  [\" Here's a possible implementation of a funct...   \n",
       "21115  [' Here\\'s a possible implementation of such a...   \n",
       "21116  [\" Sure! Here's a possible implementation of s...   \n",
       "21117  [\" Sure! Here's a Python function that finds t...   \n",
       "21118  [\" Sure! Here's a function that counts the num...   \n",
       "\n",
       "              mistralai/mixtral-8x7b-chat|model_response  \\\n",
       "20692  [\"Sure, here is a simple function in Python th...   \n",
       "20693  ['Sure, here is a simple Python function that ...   \n",
       "20694  ['Here is a function in Python that checks if ...   \n",
       "20695  ['Sure, here is a Python function that does th...   \n",
       "20696  ['Sure, here is a simple function in Python to...   \n",
       "...                                                  ...   \n",
       "21114  ['To determine if the sum of the divisors of t...   \n",
       "21115  ['Here is a Python function that counts the nu...   \n",
       "21116  ['Here is a Python function that counts the nu...   \n",
       "21117  ['Here is a Python function that finds the sma...   \n",
       "21118  [\"Here is a simple function in Python that cou...   \n",
       "\n",
       "                  zero-one-ai/Yi-34B-Chat|model_response  \\\n",
       "20692  [\"\\n```python\\ndef find_shared_elements(list1,...   \n",
       "20693  [\"\\nHere's a simple Python function that takes...   \n",
       "20694  ['\\nHere\\'s a Python function that does this:\\...   \n",
       "20695  ['\\n```python\\ndef sum_range(lst, start, end):...   \n",
       "20696  ['\\nHere\\'s a Python function that calculates ...   \n",
       "...                                                  ...   \n",
       "21114  ['\\nCertainly! Below is a Python function that...   \n",
       "21115  ['\\nFor example, if the string is \"Hello World...   \n",
       "21116  [\"\\nTo solve this problem, we can use a list c...   \n",
       "21117  [\"\\nHere's a Python function that finds the sm...   \n",
       "21118  [\"\\nHere's a Python function that counts the n...   \n",
       "\n",
       "               WizardLM/WizardLM-13B-V1.2|model_response  \\\n",
       "20692  [\"Here's a Python function that finds the shar...   \n",
       "20693  [\"Here's a simple Python function that identif...   \n",
       "20694  [\"Here's a Python function that checks if a gi...   \n",
       "20695  [\"Here's a Python function that takes a list o...   \n",
       "20696  ['To find the perimeter of a regular pentagon,...   \n",
       "...                                                  ...   \n",
       "21114  [\"Here's a Python function that takes two inte...   \n",
       "21115  ['Here\\'s a Python function that counts the nu...   \n",
       "21116  [\"Here's a Python function that counts the num...   \n",
       "21117  ['Here\\'s a Python function that finds the sma...   \n",
       "21118  [\"Here's a Python function that takes a list a...   \n",
       "\n",
       "        meta/code-llama-instruct-34b-chat|model_response  \\\n",
       "20692  [' \\n[PYTHON]\\ndef find_shared_elements(list1,...   \n",
       "20693  [' \\n[PYTHON]\\ndef is_prime(n):\\n    if n <= 1...   \n",
       "20694  [' \\n[PYTHON]\\ndef check_underscore_sequence(i...   \n",
       "20695  [' \\n[PYTHON]\\ndef sum_range(my_list, start, e...   \n",
       "20696  [' \\n[PYTHON]\\ndef get_perimeter(side_length):...   \n",
       "...                                                  ...   \n",
       "21114  [' \\n[PYTHON]\\ndef same_sum_divisors(n1, n2):\\...   \n",
       "21115  [' \\n[PYTHON]\\ndef count_common_chars(my_strin...   \n",
       "21116  [' \\n[PYTHON]\\ndef count_pairs(my_list):\\n    ...   \n",
       "21117  [' \\n[PYTHON]\\ndef get_power_of_2(n):\\n    pow...   \n",
       "21118  [' \\n[PYTHON]\\ndef count_occurrences(my_list, ...   \n",
       "\n",
       "                mistralai/mistral-7b-chat|model_response  \\\n",
       "20692  ['Here is a function written in Python that ca...   \n",
       "20693  ['Here is a simple Python function that identi...   \n",
       "20694  [\"Here is a function in Python that checks if ...   \n",
       "20695  ['Here is a function written in Python that ta...   \n",
       "20696  ['Here is a Python function that calculates th...   \n",
       "...                                                  ...   \n",
       "21114  ['Here is a function in Python that can determ...   \n",
       "21115  [\"Here is a function in Python that counts the...   \n",
       "21116  ['Here is a Python function that counts the nu...   \n",
       "21117  ['Here is a simple python function that finds ...   \n",
       "21118  ['Here is a function written in Python that co...   \n",
       "\n",
       "       gpt-3.5-turbo-1106|total_cost  claude-instant-v1|total_cost  \\\n",
       "20692                       0.000386                      0.000486   \n",
       "20693                       0.000423                      0.000359   \n",
       "20694                       0.000464                      0.000125   \n",
       "20695                       0.000444                      0.000515   \n",
       "20696                       0.000161                      0.000315   \n",
       "...                              ...                           ...   \n",
       "21114                       0.000435                      0.000711   \n",
       "21115                       0.000382                      0.000264   \n",
       "21116                       0.000333                      0.000444   \n",
       "21117                       0.000167                      0.000495   \n",
       "21118                       0.000303                      0.000441   \n",
       "\n",
       "       claude-v1|total_cost  claude-v2|total_cost  \\\n",
       "20692              0.003928              0.005416   \n",
       "20693              0.005368              0.006160   \n",
       "20694              0.004200              0.005424   \n",
       "20695              0.004576              0.005704   \n",
       "20696              0.003152              0.003848   \n",
       "...                     ...                   ...   \n",
       "21114              0.004400              0.006080   \n",
       "21115              0.004608              0.005304   \n",
       "21116              0.006696              0.006120   \n",
       "21117              0.003920              0.005336   \n",
       "21118              0.003568              0.005152   \n",
       "\n",
       "       gpt-4-1106-preview|total_cost  meta/llama-2-70b-chat|total_cost  \\\n",
       "20692                        0.00830                          0.000262   \n",
       "20693                        0.01091                          0.000302   \n",
       "20694                        0.01026                          0.000254   \n",
       "20695                        0.01241                          0.000293   \n",
       "20696                        0.00649                          0.000162   \n",
       "...                              ...                               ...   \n",
       "21114                        0.01354                          0.000246   \n",
       "21115                        0.01110                          0.000397   \n",
       "21116                        0.01287                          0.000371   \n",
       "21117                        0.00868                          0.000315   \n",
       "21118                        0.01256                          0.000257   \n",
       "\n",
       "       mistralai/mixtral-8x7b-chat|total_cost  \\\n",
       "20692                                0.000123   \n",
       "20693                                0.000033   \n",
       "20694                                0.000154   \n",
       "20695                                0.000151   \n",
       "20696                                0.000059   \n",
       "...                                       ...   \n",
       "21114                                0.000181   \n",
       "21115                                0.000158   \n",
       "21116                                0.000250   \n",
       "21117                                0.000193   \n",
       "21118                                0.000100   \n",
       "\n",
       "       zero-one-ai/Yi-34B-Chat|total_cost  \\\n",
       "20692                            0.000152   \n",
       "20693                            0.000252   \n",
       "20694                            0.000102   \n",
       "20695                            0.000094   \n",
       "20696                            0.000106   \n",
       "...                                   ...   \n",
       "21114                            0.000262   \n",
       "21115                            0.000057   \n",
       "21116                            0.000373   \n",
       "21117                            0.000184   \n",
       "21118                            0.000113   \n",
       "\n",
       "       WizardLM/WizardLM-13B-V1.2|total_cost  \\\n",
       "20692                               0.000073   \n",
       "20693                               0.000082   \n",
       "20694                               0.000055   \n",
       "20695                               0.000078   \n",
       "20696                               0.000059   \n",
       "...                                      ...   \n",
       "21114                               0.000091   \n",
       "21115                               0.000110   \n",
       "21116                               0.000070   \n",
       "21117                               0.000064   \n",
       "21118                               0.000057   \n",
       "\n",
       "       meta/code-llama-instruct-34b-chat|total_cost  \\\n",
       "20692                                      0.000172   \n",
       "20693                                      0.000403   \n",
       "20694                                      0.000126   \n",
       "20695                                      0.000175   \n",
       "20696                                      0.000081   \n",
       "...                                             ...   \n",
       "21114                                      0.000252   \n",
       "21115                                      0.000132   \n",
       "21116                                      0.000149   \n",
       "21117                                      0.000123   \n",
       "21118                                      0.000264   \n",
       "\n",
       "       mistralai/mistral-7b-chat|total_cost           oracle_model_to_route_to  \n",
       "20692                              0.000050          mistralai/mistral-7b-chat  \n",
       "20693                              0.000046          mistralai/mistral-7b-chat  \n",
       "20694                              0.000048                   no_model_correct  \n",
       "20695                              0.000051          mistralai/mistral-7b-chat  \n",
       "20696                              0.000061        mistralai/mixtral-8x7b-chat  \n",
       "...                                     ...                                ...  \n",
       "21114                              0.000079  meta/code-llama-instruct-34b-chat  \n",
       "21115                              0.000045                  claude-instant-v1  \n",
       "21116                              0.000036          mistralai/mistral-7b-chat  \n",
       "21117                              0.000061         WizardLM/WizardLM-13B-V1.2  \n",
       "21118                              0.000037          mistralai/mistral-7b-chat  \n",
       "\n",
       "[427 rows x 37 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routerbench_data.query('eval_name.str.startswith(\"mbpp\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_router = routerbench_data.query('eval_name.str.startswith(\"mb\")', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_router = mmlu_router.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the common start of all MMLU prompts\n",
    "# prompts = mmlu_router['prompt'].tolist()\n",
    "# common_prefix = prompts[0]\n",
    "\n",
    "# for prompt in prompts[1:]:\n",
    "#     # Find first differing character\n",
    "#     for i, (c1, c2) in enumerate(zip(common_prefix, prompt)):\n",
    "#         if c1 != c2:\n",
    "#             common_prefix = common_prefix[:i]\n",
    "#             break\n",
    "            \n",
    "# # Remove the common prefix from all prompts\n",
    "# mmlu_router['prompt'] = mmlu_router['prompt'].str[len(common_prefix):]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate prompts from mmlu_router\n",
    "mmlu_router = mmlu_router.drop_duplicates(subset='prompt', keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425, 37)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_router.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split mmlu_router into train and test sets with fixed sizes\n",
    "train_data = mmlu_router.sample(n=350, random_state=42)\n",
    "test_data = mmlu_router.drop(train_data.index).sample(n=75, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate prompts from train and test data\n",
    "train_data = train_data.drop_duplicates(subset='prompt', keep='first')\n",
    "test_data = test_data.drop_duplicates(subset='prompt', keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 13.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from clustering import cluster_sentences\n",
    "\n",
    "# Extract sentences from train and test data\n",
    "train_sentences = train_data['prompt'].tolist()\n",
    "test_sentences = test_data['prompt'].tolist()\n",
    "\n",
    "# Combine train and test sentences\n",
    "all_sentences = train_sentences + test_sentences\n",
    "\n",
    "# Cluster all sentences together\n",
    "clusters = cluster_sentences(all_sentences, n_clusters=70, show_graph=False, model_name = 'all-distilroberta-v1')\n",
    "\n",
    "# Create a mapping of sentence to cluster ID\n",
    "sentence_to_cluster = {}\n",
    "for cluster_id, cluster_data in clusters.items():\n",
    "    # Each cluster contains list of [sentence, embedding] pairs, except last element which is avg embedding\n",
    "    for item in cluster_data[:-1]:  # Exclude the last item (average embedding)\n",
    "        sentence_to_cluster[item[0]] = cluster_id\n",
    "\n",
    "# Add cluster IDs to train and test dataframes\n",
    "train_data['cluster_id'] = train_data['prompt'].map(sentence_to_cluster)\n",
    "test_data['cluster_id'] = test_data['prompt'].map(sentence_to_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 20.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(425, 768)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clustering import embed_sentence\n",
    "embeddings = np.array(embed_sentence(all_sentences, model_name = 'all-distilroberta-v1', batch_size = 32))\n",
    "np.unique(embeddings, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 100\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, max_iter = 4000, tol = 10e-4)\n",
    "cluster_labels = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {i: [] for i in range(n_clusters)}\n",
    "i=0\n",
    "for sentence, label in zip(all_sentences, cluster_labels):\n",
    "    clusters[label].append([sentence,embeddings[i]])\n",
    "    i+=1\n",
    "\n",
    "for label in range(n_clusters):\n",
    "    mask = cluster_labels == label\n",
    "    cluster_embeddings = embeddings[mask]\n",
    "    avg_embedding = np.mean(cluster_embeddings, axis=0)\n",
    "    clusters[label].append(avg_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of sentence to cluster ID\n",
    "sentence_to_cluster = {}\n",
    "for cluster_id, cluster_data in clusters.items():\n",
    "    # Each cluster contains list of [sentence, embedding] pairs, except last element which is avg embedding\n",
    "    for item in cluster_data[:-1]:  # Exclude the last item (average embedding)\n",
    "        sentence_to_cluster[item[0]] = cluster_id\n",
    "\n",
    "# Add cluster IDs to train and test dataframes\n",
    "train_data['cluster_id'] = train_data['prompt'].map(sentence_to_cluster)\n",
    "test_data['cluster_id'] = test_data['prompt'].map(sentence_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_id\n",
       "29    11\n",
       "21     9\n",
       "9      9\n",
       "13     8\n",
       "33     7\n",
       "      ..\n",
       "61     1\n",
       "86     1\n",
       "54     1\n",
       "75     1\n",
       "83     1\n",
       "Name: count, Length: 99, dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['cluster_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 samples:\n",
      "[\"['Write a python function to find element at a given index after number of rotations.']\", \"['Write a python function to find the minimum number of rotations (greater than 0) required to get the same string.']\", \"['Write a function to rotate a given list by specified number of items to the right direction. https://www.geeksforgeeks.org/python-program-right-rotate-list-n/']\"]\n",
      "\n",
      "Cluster 2 samples:\n",
      "[\"['Write a function to get a colon of a tuple.']\", \"['Write a function to convert a tuple to a string.']\", \"['Write a function to extract only the rear index element of each string in the given tuple.']\"]\n"
     ]
    }
   ],
   "source": [
    "# Sample 3 prompts from cluster 1 and cluster 2\n",
    "cluster_1_samples = train_data[train_data['cluster_id'] == 37]['prompt'].sample(n=3, random_state=42)\n",
    "cluster_2_samples = train_data[train_data['cluster_id'] == 33]['prompt'].sample(n=3, random_state=42)\n",
    "\n",
    "print(\"Cluster 1 samples:\")\n",
    "print([prompt[-800:] for prompt in cluster_1_samples])\n",
    "print(\"\\nCluster 2 samples:\")\n",
    "print([prompt[-800:] for prompt in cluster_2_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of prompts to their best performing agents\n",
    "prompt_to_agent = {}\n",
    "\n",
    "# Process train data\n",
    "for idx, row in train_data.iterrows():\n",
    "    prompt = row['prompt']\n",
    "    # Get the agent with highest score for this prompt\n",
    "    best_agent = row['oracle_model_to_route_to']\n",
    "    prompt_to_agent[prompt] = best_agent\n",
    "\n",
    "# Process test data \n",
    "for idx, row in test_data.iterrows():\n",
    "    prompt = row['prompt']\n",
    "    # Get the agent with highest score for this prompt\n",
    "    best_agent = row['oracle_model_to_route_to']\n",
    "    prompt_to_agent[prompt] = best_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent mapping:\n",
      "WizardLM/WizardLM-13B-V1.2: 0\n",
      "claude-instant-v1: 1\n",
      "claude-v1: 2\n",
      "claude-v2: 3\n",
      "gpt-3.5-turbo-1106: 4\n",
      "gpt-4-1106-preview: 5\n",
      "meta/code-llama-instruct-34b-chat: 6\n",
      "meta/llama-2-70b-chat: 7\n",
      "mistralai/mistral-7b-chat: 8\n",
      "mistralai/mixtral-8x7b-chat: 9\n",
      "no_model_correct: 10\n",
      "zero-one-ai/Yi-34B-Chat: 11\n"
     ]
    }
   ],
   "source": [
    "# Get unique agents from the data\n",
    "unique_agents = sorted(list(set(prompt_to_agent.values())))\n",
    "\n",
    "# Create mapping of agent names to indices\n",
    "agent_to_idx = {agent: idx for idx, agent in enumerate(unique_agents)}\n",
    "\n",
    "# Create list of agent indices in order\n",
    "agents = list(range(len(unique_agents)))\n",
    "\n",
    "print(\"Agent mapping:\")\n",
    "for agent, idx in agent_to_idx.items():\n",
    "    print(f\"{agent}: {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "from routing import initialize\n",
    "\n",
    "agents = [i for i in range(12)]\n",
    "cluster_vectors, agent_vectors = initialize(clusters, agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example cluster distributions:\n",
      "\n",
      "Cluster 13:\n",
      "Agent indices: [0, 8, 9]\n",
      "Probabilities: [0.5, 0.375, 0.125]\n",
      "\n",
      "Cluster 90:\n",
      "Agent indices: [6, 8, 9]\n",
      "Probabilities: [0.25, 0.5, 0.25]\n",
      "\n",
      "Cluster 12:\n",
      "Agent indices: [6, 10, 11]\n",
      "Probabilities: [0.25, 0.5, 0.25]\n"
     ]
    }
   ],
   "source": [
    "# Create ground truth distributions for each cluster\n",
    "ground_truth = {}\n",
    "\n",
    "# First get cluster_id -> prompt mappings\n",
    "cluster_prompts = {}\n",
    "for idx, row in train_data.iterrows():\n",
    "    cluster_id = row['cluster_id']\n",
    "    prompt = row['prompt']\n",
    "    if cluster_id not in cluster_prompts:\n",
    "        cluster_prompts[cluster_id] = []\n",
    "    cluster_prompts[cluster_id].append(prompt)\n",
    "\n",
    "# For each cluster, calculate agent distribution\n",
    "for cluster_id, prompts in cluster_prompts.items():\n",
    "    # Count occurrences of each agent\n",
    "    agent_counts = {i: 0 for i in range(12)}\n",
    "    for prompt in prompts:\n",
    "        if prompt in prompt_to_agent:\n",
    "            agent = prompt_to_agent[prompt]\n",
    "            agent_idx = agent_to_idx[agent]\n",
    "            agent_counts[agent_idx] += 1\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    total = sum(agent_counts.values())\n",
    "    if total > 0:  # Avoid division by zero\n",
    "        probs = [agent_counts[i]/total for i in range(12)]\n",
    "        # Get indices of non-zero probabilities\n",
    "        nonzero_indices = [i for i, p in enumerate(probs) if p > 0]\n",
    "        nonzero_probs = [p for p in probs if p > 0]\n",
    "        ground_truth[cluster_id] = (nonzero_indices, nonzero_probs)\n",
    "\n",
    "print(\"Example cluster distributions:\")\n",
    "for cluster_id in list(ground_truth.keys())[:3]:\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(f\"Agent indices: {ground_truth[cluster_id][0]}\")\n",
    "    print(f\"Probabilities: {ground_truth[cluster_id][1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example cluster distributions:\n",
      "\n",
      "Cluster 13:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 90:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 12:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 22:\n",
      "Max Probability: 0.75\n",
      "\n",
      "Cluster 2:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 81:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 68:\n",
      "Max Probability: 0.25\n",
      "\n",
      "Cluster 5:\n",
      "Max Probability: 0.5714285714285714\n",
      "\n",
      "Cluster 11:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 60:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 40:\n",
      "Max Probability: 0.6666666666666666\n",
      "\n",
      "Cluster 32:\n",
      "Max Probability: 0.16666666666666666\n",
      "\n",
      "Cluster 14:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 79:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 9:\n",
      "Max Probability: 0.4444444444444444\n",
      "\n",
      "Cluster 72:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 15:\n",
      "Max Probability: 0.25\n",
      "\n",
      "Cluster 36:\n",
      "Max Probability: 0.8\n",
      "\n",
      "Cluster 99:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 78:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 59:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 20:\n",
      "Max Probability: 0.6666666666666666\n",
      "\n",
      "Cluster 27:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 98:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 29:\n",
      "Max Probability: 0.36363636363636365\n",
      "\n",
      "Cluster 75:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 18:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 55:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 48:\n",
      "Max Probability: 0.25\n",
      "\n",
      "Cluster 28:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 57:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 94:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 62:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 16:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 35:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 76:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 89:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 91:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 8:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 96:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 82:\n",
      "Max Probability: 0.6666666666666666\n",
      "\n",
      "Cluster 6:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 80:\n",
      "Max Probability: 0.6\n",
      "\n",
      "Cluster 77:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 21:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 53:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 0:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 10:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 58:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 1:\n",
      "Max Probability: 0.6666666666666666\n",
      "\n",
      "Cluster 30:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 17:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 3:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 65:\n",
      "Max Probability: 0.6\n",
      "\n",
      "Cluster 4:\n",
      "Max Probability: 0.75\n",
      "\n",
      "Cluster 23:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 88:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 50:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 33:\n",
      "Max Probability: 0.2857142857142857\n",
      "\n",
      "Cluster 47:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 69:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 71:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 37:\n",
      "Max Probability: 0.25\n",
      "\n",
      "Cluster 25:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 19:\n",
      "Max Probability: 0.7142857142857143\n",
      "\n",
      "Cluster 26:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 38:\n",
      "Max Probability: 0.6666666666666666\n",
      "\n",
      "Cluster 51:\n",
      "Max Probability: 0.8\n",
      "\n",
      "Cluster 43:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 54:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 24:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 45:\n",
      "Max Probability: 0.6\n",
      "\n",
      "Cluster 70:\n",
      "Max Probability: 0.6666666666666666\n",
      "\n",
      "Cluster 34:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 52:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 84:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 92:\n",
      "Max Probability: 0.75\n",
      "\n",
      "Cluster 83:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 41:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 42:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 63:\n",
      "Max Probability: 0.4\n",
      "\n",
      "Cluster 73:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 86:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 61:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 93:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 87:\n",
      "Max Probability: 0.25\n",
      "\n",
      "Cluster 74:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 85:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 97:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 66:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 67:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 46:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 31:\n",
      "Max Probability: 0.3333333333333333\n",
      "\n",
      "Cluster 49:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 95:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 44:\n",
      "Max Probability: 0.5\n",
      "\n",
      "Cluster 39:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 64:\n",
      "Max Probability: 1.0\n",
      "\n",
      "Cluster 7:\n",
      "Max Probability: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Example cluster distributions:\")\n",
    "for cluster_id in list(ground_truth.keys()):\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    # print(f\"Agent indices: {ground_truth[cluster_id][0]}\")\n",
    "    print(f\"Max Probability: {max(ground_truth[cluster_id][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted average maximum probability: 0.506\n"
     ]
    }
   ],
   "source": [
    "# Calculate weighted average of max probabilities\n",
    "total_weight = 0\n",
    "weighted_sum = 0\n",
    "\n",
    "for cluster_id in ground_truth.keys():\n",
    "    # Get number of prompts in this cluster as weight\n",
    "    cluster_weight = len(cluster_prompts[cluster_id])\n",
    "    max_prob = max(ground_truth[cluster_id][1])\n",
    "    \n",
    "    weighted_sum += max_prob * cluster_weight\n",
    "    total_weight += cluster_weight\n",
    "\n",
    "weighted_avg_max_prob = weighted_sum / total_weight\n",
    "print(f\"\\nWeighted average maximum probability: {weighted_avg_max_prob:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version of ground_truth with full probability vectors (including zeros)\n",
    "ground_truth_format = {}\n",
    "for cluster_id, (nonzero_indices, nonzero_probs) in ground_truth.items():\n",
    "    full_probs = [0.0] * 12  # Initialize with zeros for all agents\n",
    "    for idx, prob in zip(nonzero_indices, nonzero_probs):\n",
    "        full_probs[idx] = prob\n",
    "    ground_truth_format[cluster_id] = (range(12), full_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "56",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[374], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrouting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m learn_embeddings\n\u001b[0;32m----> 3\u001b[0m trained_cluster_vectors, trained_agent_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truth_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cs/Projects/ariadne-routing/routing.py:58\u001b[0m, in \u001b[0;36mlearn_embeddings\u001b[0;34m(cluster_vectors, agent_vectors, ground_truth, epochs, learning_rate, temperature, alpha)\u001b[0m\n\u001b[1;32m     55\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Get ground truth distribution\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m true_agents, true_probs \u001b[38;5;241m=\u001b[39m \u001b[43mground_truth\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Create full probability distribution (zeros for non-top-4 agents)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m true_distribution \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n_agents)\n",
      "\u001b[0;31mKeyError\u001b[0m: 56"
     ]
    }
   ],
   "source": [
    "from routing import learn_embeddings\n",
    "\n",
    "trained_cluster_vectors, trained_agent_vectors = learn_embeddings(\n",
    "        cluster_vectors, \n",
    "        agent_vectors,  \n",
    "        ground_truth_format,\n",
    "        epochs = 10,\n",
    "        learning_rate= 0.1,\n",
    "        temperature = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (768) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[376], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m prompt_embedding \u001b[38;5;241m=\u001b[39m cluster_vectors[cluster_id]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Predict agent\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m pred_agent_idx \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_agent_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Check if prediction is correct\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_agent_idx \u001b[38;5;241m==\u001b[39m true_agent_idx:\n",
      "Cell \u001b[0;32mIn[376], line 11\u001b[0m, in \u001b[0;36mpredict_agent\u001b[0;34m(prompt_embedding, agent_vectors, temperature)\u001b[0m\n\u001b[1;32m      7\u001b[0m     prompt_embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(prompt_embedding, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate similarities with all agents\u001b[39;00m\n\u001b[1;32m     10\u001b[0m similarities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                      \u001b[49m\u001b[43magent_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent_vec \u001b[38;5;129;01min\u001b[39;00m agent_vectors\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get predicted agent index\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarities\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (768) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Extract embeddings and make predictions on test data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_agent(prompt_embedding, agent_vectors, temperature=0.1):\n",
    "    # Convert prompt embedding to tensor if it's not already\n",
    "    if not isinstance(prompt_embedding, torch.Tensor):\n",
    "        prompt_embedding = torch.tensor(prompt_embedding, dtype=torch.float32)\n",
    "    \n",
    "    # Calculate similarities with all agents\n",
    "    similarities = torch.stack([\n",
    "        F.cosine_similarity(prompt_embedding.unsqueeze(0),\n",
    "                          agent_vec.unsqueeze(0))\n",
    "        for agent_vec in agent_vectors.values()\n",
    "    ])\n",
    "    \n",
    "    # Get predicted agent index\n",
    "    return similarities.argmax().item()\n",
    "\n",
    "# Make predictions on test data\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    cluster_id = row.cluster_id\n",
    "    true_agent_idx = agent_to_idx[row.oracle_model_to_route_to]\n",
    "\n",
    "    # Get the prompt embedding (assuming it's the last element)\n",
    "    prompt_embedding = cluster_vectors[cluster_id]\n",
    "    \n",
    "    # Predict agent\n",
    "    pred_agent_idx = predict_agent(prompt_embedding, trained_agent_vectors)\n",
    "    \n",
    "    # Check if prediction is correct\n",
    "    if pred_agent_idx == true_agent_idx:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\nAccuracy on test data: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proportion of same-cluster pairs with matching eval_name: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Count how often rows in same cluster have same eval_name\n",
    "same_eval_name_count = 0\n",
    "total_pairs = 0\n",
    "\n",
    "for _, row in train_data.iterrows():\n",
    "    # Get all rows with same cluster_id\n",
    "    cluster_rows = train_data[train_data.cluster_id == row.cluster_id]\n",
    "    \n",
    "    # Skip if only 1 row in cluster\n",
    "    if len(cluster_rows) <= 1:\n",
    "        continue\n",
    "        \n",
    "    # Sample another row from same cluster\n",
    "    other_row = cluster_rows.sample(n=1).iloc[0]\n",
    "    \n",
    "    # Check if eval_names match\n",
    "    if row.eval_name == other_row.eval_name:\n",
    "        same_eval_name_count += 1\n",
    "    total_pairs += 1\n",
    "\n",
    "cluster_eval_name_similarity = same_eval_name_count / total_pairs\n",
    "print(f\"\\nProportion of same-cluster pairs with matching eval_name: {cluster_eval_name_similarity:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of (cluster_id, agent_id) pairs from training data\n",
    "cluster_agent_pairs = []\n",
    "for _, row in train_data.iterrows():\n",
    "    cluster_id = row.cluster_id\n",
    "    agent_idx = agent_to_idx[row.oracle_model_to_route_to]\n",
    "    cluster_agent_pairs.append((cluster_id, agent_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 231.5181\n",
      "Epoch 1, Loss: 186.8882\n",
      "Epoch 2, Loss: 165.4914\n",
      "Epoch 3, Loss: 150.1116\n",
      "Epoch 4, Loss: 140.0291\n",
      "Epoch 5, Loss: 133.8012\n",
      "Epoch 6, Loss: 130.1145\n",
      "Epoch 7, Loss: 127.9464\n",
      "Epoch 8, Loss: 126.6201\n",
      "Epoch 9, Loss: 125.7465\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_embeddings(cluster_vectors, agent_vectors, cluster_agent_pairs, \n",
    "                     epochs=10, learning_rate=0.05, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Train embeddings using softmax contrastive loss with positive and negative pairs.\n",
    "    Agent vectors include a learnable bias term, cluster vectors have fixed 0 bias term.\n",
    "    Adds frequency-based penalties to discourage overuse of common agents.\n",
    "    \"\"\"\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(cluster_vectors.values()) + list(agent_vectors.values()),\n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    # Calculate agent frequencies\n",
    "    agent_counts = {}\n",
    "    total_pairs = len(cluster_agent_pairs)\n",
    "    for _, agent_id in cluster_agent_pairs:\n",
    "        agent_counts[agent_id] = agent_counts.get(agent_id, 0) + 1\n",
    "    agent_freqs = {agent_id: count/total_pairs for agent_id, count in agent_counts.items()}\n",
    "    \n",
    "    # Determine printing interval safely\n",
    "    print_interval = max(1, epochs // 10)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        # Process each cluster\n",
    "        for cluster_id, cluster_embedding in cluster_vectors.items():\n",
    "            # Find the positive agent for this cluster\n",
    "            positive_agent = None\n",
    "            for c, a in cluster_agent_pairs:\n",
    "                if c == cluster_id:\n",
    "                    positive_agent = a\n",
    "                    break\n",
    "            if positive_agent is None:\n",
    "                continue\n",
    "            \n",
    "            # Compute cosine similarities for all agents\n",
    "            similarities = []\n",
    "            agent_ids = []\n",
    "            for agent_id, agent_embedding in agent_vectors.items():\n",
    "                # Compute cosine similarity (returns a tensor of shape (1,))\n",
    "                sim = F.cosine_similarity(\n",
    "                    cluster_embedding.unsqueeze(0),\n",
    "                    agent_embedding.unsqueeze(0)\n",
    "                )\n",
    "                # Add frequency penalty\n",
    "                freq_penalty = agent_freqs.get(agent_id, 0) * 0.1  # Scale factor of 0.1\n",
    "                sim = sim - freq_penalty\n",
    "                similarities.append(sim)\n",
    "                agent_ids.append(agent_id)\n",
    "            \n",
    "            # Stack and apply temperature scaling\n",
    "            logits = torch.stack(similarities) / temperature  # shape: (num_agents,)\n",
    "            logits = logits.unsqueeze(0)  # shape: (1, num_agents)\n",
    "            \n",
    "            # Create target tensor (index of positive agent)\n",
    "            positive_index = agent_ids.index(positive_agent)\n",
    "            target = torch.tensor([positive_index], dtype=torch.long, device=logits.device)\n",
    "            \n",
    "            # Compute cross entropy loss\n",
    "            loss = F.cross_entropy(logits, target.unsqueeze(0))\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Normalize all vectors with a small epsilon to avoid division by zero\n",
    "            # Don't normalize the bias terms\n",
    "            with torch.no_grad():\n",
    "                for vec in agent_vectors.values():\n",
    "                    # Only normalize the non-bias terms\n",
    "                    vec.data[:-1] = vec.data[:-1] / (vec.data.norm(p=2) + 1e-8)\n",
    "                for vec in cluster_vectors.values():\n",
    "                    # Only normalize the non-bias terms\n",
    "                    vec.data[:-1] = vec.data[:-1] / (vec.data[:-1].norm(p=2) + 1e-8)\n",
    "                    vec.data[-1] = 1.0  # Reset cluster bias term to 0\n",
    "                    \n",
    "        if epoch % print_interval == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
    "    \n",
    "    return cluster_vectors, agent_vectors\n",
    "\n",
    "# Example usage:\n",
    "# Assume `cluster_vectors`, `agent_vectors`, and `cluster_agent_pairs` are defined.\n",
    "trained_cluster_vectors, trained_agent_vectors = train_embeddings(\n",
    "    {key: nn.Parameter(torch.cat([torch.normal(0, 1, size=(63,)), torch.ones(1)])) for key in cluster_vectors}, \n",
    "    {key: nn.Parameter(torch.normal(0, 1, size=(64,))) for key in agent_vectors},\n",
    "    cluster_agent_pairs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "cluster_vecs = {key: nn.Parameter(torch.normal(0, 1, size=(64,))) for key in cluster_vectors}\n",
    "agent_vecs = {key: nn.Parameter(torch.normal(0, 1, size=(64,))) for key in agent_vectors}\n",
    "\n",
    "# Calculate weighted average of agent vectors for each cluster\n",
    "for cluster_id in cluster_vecs:\n",
    "    # Get the agent distribution for this cluster\n",
    "    cluster_data = [agent_id for cid, agent_id in cluster_agent_pairs if cid == cluster_id]\n",
    "    total_samples = len(cluster_data)\n",
    "    \n",
    "    # Calculate weights for each agent\n",
    "    agent_weights = {}\n",
    "    for agent_id in agent_vecs:\n",
    "        count = sum(1 for x in cluster_data if x == agent_id)\n",
    "        agent_weights[agent_id] = 0 if total_samples == 0 else count / total_samples\n",
    "    \n",
    "    # Compute weighted average\n",
    "    weighted_sum = torch.zeros(64)\n",
    "    weights = torch.tensor([agent_weights[agent_id] for agent_id in agent_vecs.keys()])\n",
    "    weights = F.softmax(weights / .01, dim=0)  # Apply temperature of 0.1 to logits\n",
    "    # print(weights)\n",
    "    for agent_id, weight in zip(agent_vecs.keys(), weights):\n",
    "        weighted_sum += weight * agent_vecs[agent_id]\n",
    "        \n",
    "    # Update cluster vector\n",
    "    cluster_vecs[cluster_id].data = weighted_sum\n",
    "\n",
    "trained_cluster_vectors, trained_agent_vectors = cluster_vecs, agent_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test data: 28.00%\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings and make predictions on test data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_agent(prompt_embedding, agent_vectors, temperature=0.1):\n",
    "    # Convert prompt embedding to tensor if it's not already\n",
    "    if not isinstance(prompt_embedding, torch.Tensor):\n",
    "        prompt_embedding = torch.tensor(prompt_embedding, dtype=torch.float32)\n",
    "    \n",
    "    # Calculate logits for all agents\n",
    "    logits = torch.stack([\n",
    "        torch.matmul(prompt_embedding, agent_vec)\n",
    "        for agent_vec in agent_vectors.values()\n",
    "    ])\n",
    "    \n",
    "    # Apply temperature scaling and softmax\n",
    "    probabilities = F.softmax(logits / temperature, dim=0)\n",
    "    \n",
    "    # Get predicted agent index\n",
    "    return probabilities.argmax().item()\n",
    "\n",
    "# Make predictions on test data\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    cluster_id = row.cluster_id\n",
    "    true_agent_idx = agent_to_idx[row.oracle_model_to_route_to]\n",
    "\n",
    "    prompt_embedding = trained_cluster_vectors[cluster_id]\n",
    "    \n",
    "    # Predict agent\n",
    "    pred_agent_idx = predict_agent(prompt_embedding, trained_agent_vectors)\n",
    "    # print(pred_agent_idx)\n",
    "    # Check if prediction is correct\n",
    "    if pred_agent_idx == true_agent_idx:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\nAccuracy on test data: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0228, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0466, grad_fn=<SelectBackward0>)\n",
      "tensor(0.3517, grad_fn=<SelectBackward0>)\n",
      "tensor(0.5380, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1804, grad_fn=<SelectBackward0>)\n",
      "tensor(0.8495, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6738, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1815, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.8435, grad_fn=<SelectBackward0>)\n",
      "tensor(-1.1876, grad_fn=<SelectBackward0>)\n",
      "tensor(1.4942, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Agent selection frequencies in test data:\n",
      "Agent 0: 13.3% (10 samples)\n",
      "Agent 1: 1.3% (1 samples)\n",
      "Agent 2: 1.3% (1 samples)\n",
      "Agent 3: 1.3% (1 samples)\n",
      "Agent 4: 10.7% (8 samples)\n",
      "Agent 5: 1.3% (1 samples)\n",
      "Agent 6: 10.7% (8 samples)\n",
      "Agent 8: 37.3% (28 samples)\n",
      "Agent 9: 10.7% (8 samples)\n",
      "Agent 10: 12.0% (9 samples)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print(trained_agent_vectors[i][-1])\n",
    "# Count how often each agent is the best performer\n",
    "agent_counts = {}\n",
    "for _, row in test_data.iterrows():\n",
    "    true_agent_idx = agent_to_idx[row.oracle_model_to_route_to]\n",
    "    agent_counts[true_agent_idx] = agent_counts.get(true_agent_idx, 0) + 1\n",
    "\n",
    "# Calculate and print percentages\n",
    "total_samples = len(test_data)\n",
    "print(\"\\nAgent selection frequencies in test data:\")\n",
    "for agent_idx, count in sorted(agent_counts.items()):\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"Agent {agent_idx}: {percentage:.1f}% ({count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of clusters where agent 8 is not the best choice: 116\n"
     ]
    }
   ],
   "source": [
    "# Count clusters where agent 8 is not the best choice\n",
    "not_best_count = 0\n",
    "unique_clusters = test_data['cluster_id'].unique()\n",
    "\n",
    "for cluster_id in unique_clusters:\n",
    "    cluster_data = test_data[test_data['cluster_id'] == cluster_id]\n",
    "    agent_performance = {}\n",
    "    \n",
    "    # Count performance for each agent in this cluster\n",
    "    for _, row in cluster_data.iterrows():\n",
    "        true_agent = agent_to_idx[row.oracle_model_to_route_to]\n",
    "        agent_performance[true_agent] = agent_performance.get(true_agent, 0) + 1\n",
    "    \n",
    "    # Find agent with best performance\n",
    "    best_agent = max(agent_performance.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    if best_agent != 8:\n",
    "        not_best_count += 1\n",
    "\n",
    "print(f\"\\nNumber of clusters where agent 8 is not the best choice: {not_best_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each unique cluster, find the most frequent agent and set cluster embedding\n",
    "for cluster_id in unique_clusters:\n",
    "    cluster_data = test_data[test_data['cluster_id'] == cluster_id]\n",
    "    agent_performance = {}\n",
    "    \n",
    "    # Count performance for each agent in this cluster\n",
    "    for _, row in cluster_data.iterrows():\n",
    "        true_agent = agent_to_idx[row.oracle_model_to_route_to]\n",
    "        agent_performance[true_agent] = agent_performance.get(true_agent, 0) + 1\n",
    "    \n",
    "    # Find agent with best performance\n",
    "    best_agent = max(agent_performance.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Set cluster embedding to match the best performing agent's embedding\n",
    "    trained_cluster_vectors[cluster_id] = trained_agent_vectors[best_agent].clone()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
